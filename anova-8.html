<!DOCTYPE html>
<html>
<head>
  <title>Factorial ANOVA</title>

  <meta charset="utf-8">
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="generator" content="pandoc" />




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">

  <base target="_blank">

  <script type="text/javascript">
    var SLIDE_CONFIG = {
      // Slide settings
      settings: {
                title: 'Factorial ANOVA',
                        useBuilds: true,
        usePrettify: true,
        enableSlideAreas: true,
        enableTouch: true,
                      },

      // Author information
      presenters: [
            ]
    };
  </script>

  <link href="site_libs/ioslides-13.5.1/fonts/fonts.css" rel="stylesheet" />
  <link href="site_libs/ioslides-13.5.1/theme/css/default.css" rel="stylesheet" />
  <link href="site_libs/ioslides-13.5.1/theme/css/phone.css" rel="stylesheet" />
  <script src="site_libs/ioslides-13.5.1/js/modernizr.custom.45394.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/prettify/prettify.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/prettify/lang-r.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/prettify/lang-yaml.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/hammer.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/slide-controller.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/slide-deck.js"></script>

  <style type="text/css">

    b, strong {
      font-weight: bold;
    }

    em {
      font-style: italic;
    }

    summary {
      display: list-item;
    }

    slides > slide {
      -webkit-transition: all 0.4s ease-in-out;
      -moz-transition: all 0.4s ease-in-out;
      -o-transition: all 0.4s ease-in-out;
      transition: all 0.4s ease-in-out;
    }

    .auto-fadein {
      -webkit-transition: opacity 0.6s ease-in;
      -webkit-transition-delay: 0.4s;
      -moz-transition: opacity 0.6s ease-in 0.4s;
      -o-transition: opacity 0.6s ease-in 0.4s;
      transition: opacity 0.6s ease-in 0.4s;
      opacity: 0;
    }

  </style>


</head>

<body style="opacity: 0">

<slides class="layout-widescreen">

  <slide class="title-slide segue nobackground">
        <!-- The content of this hgroup is replaced programmatically through the slide_config.json. -->
    <hgroup class="auto-fadein">
      <h1 data-config-title><!-- populated from slide_config.json --></h1>
      <h2 data-config-subtitle><!-- populated from slide_config.json --></h2>
      <p data-config-presenter><!-- populated from slide_config.json --></p>
          </hgroup>
  </slide>

<slide class=""><hgroup><h2>factorial ANOVA</h2></hgroup><article  id="factorial-anova">

<ul>
<li>Between subjects (vs within) is where everyone is assigned to 1 group</li>
<li>2-way = 2 IVs, 3-way = 3 IVs, etc</li>
<li>Advantages include: 1) efficiency 2) generalizability 3) interactions</li>
</ul>

</article></slide><slide class=""><hgroup><h2>factorial ANOVA</h2></hgroup><article  id="factorial-anova-1">

<table class = 'rmdtable'>
<tr class="header">
<th align="left"></th>
<th align="left"></th>
<th align="left">Factor</th>
<th align="left">A</th>
<th align="left">Marginal Means</th>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left"></td>
<td align="left">Tx</td>
<td align="left">Control</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">B</td>
<td align="left">neutral</td>
<td align="left">7.6</td>
<td align="left">5.0</td>
<td align="left">6.33</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left">sad</td>
<td align="left">8.3</td>
<td align="left">5.0</td>
<td align="left">6.66</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">happy</td>
<td align="left">7.3</td>
<td align="left">8.0</td>
<td align="left">7.66</td>
</tr>
<tr class="odd">
<td align="left">______</td>
<td align="left">_______</td>
<td align="left">______</td>
<td align="left">____________</td>
<td align="left">______________________</td>
</tr>
<tr class="even">
<td align="left">M.M</td>
<td align="left"></td>
<td align="left">7.77</td>
<td align="left">6.0</td>
<td align="left">6.88</td>
</tr>
</table>

</article></slide><slide class=""><hgroup><h2>A note on terminology</h2></hgroup><article  id="a-note-on-terminology">

<ul>
<li>This is just regression with multiple nominal IVs</li>
<li>Discussed as a different from regression because of historical reasons</li>
</ul>

</article></slide><slide class=""><hgroup><h2>SS decomposition</h2></hgroup><article  id="ss-decomposition">

<ul>
<li>SStotal = SSbetween + SSwithin<br/></li>
<li>SSbetween into three (or more) components (A,B,AxB)</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Marginal vs cell means</h2></hgroup><article  id="marginal-vs-cell-means">

<table class = 'rmdtable'>
<tr class="header">
<th align="left"></th>
<th align="left"></th>
<th align="left">Factor</th>
<th align="left">A</th>
<th align="left">Marginal Means</th>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left"></td>
<td align="left">Tx</td>
<td align="left">Control</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">B</td>
<td align="left">neutral</td>
<td align="left">7.6</td>
<td align="left">5.0</td>
<td align="left">6.33</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left">sad</td>
<td align="left">8.3</td>
<td align="left">5.0</td>
<td align="left">6.66</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">happy</td>
<td align="left">7.3</td>
<td align="left">8.0</td>
<td align="left">7.66</td>
</tr>
<tr class="odd">
<td align="left">______</td>
<td align="left">_______</td>
<td align="left">______</td>
<td align="left">____________</td>
<td align="left">______________________</td>
</tr>
<tr class="even">
<td align="left">M.M</td>
<td align="left"></td>
<td align="left">7.77</td>
<td align="left">6.0</td>
<td align="left">6.88</td>
</tr>
</table>

<ul>
<li>marginal for main effects<br/></li>
<li>cell means for interaction</li>
</ul>

</article></slide><slide class=""><hgroup><h2>what do interactions with nominal data look like?</h2></hgroup><article  id="what-do-interactions-with-nominal-data-look-like">

<ul>
<li>and can I &ldquo;see&rdquo; main effects too?</li>
</ul>

</article></slide><slide class=""><hgroup><h2>coneptual equation</h2></hgroup><article  id="coneptual-equation">

<ul>
<li>similar to effect coding within regression</li>
</ul>

<p>\[ Y_{ijk} = \mu + \alpha_{j} + \beta_{k} + \alpha \beta_{jk}+\varepsilon_{ijk} \]</p>

<p>\[ \alpha_{j} =  \mu_{j} -  \mu \]</p>

</article></slide><slide class=""><hgroup><h2>interactions</h2></hgroup><article  id="interactions">

<ul>
<li>main effects are on the marginal means<br/></li>
<li>interactions are about the cell means<br/></li>
<li>what is not expected based on the main effects (marginal means)</li>
<li>similar to contingency table tests of independence from last semester</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Interpretting interactions part 1</h2></hgroup><article  id="interpretting-interactions-part-1">

<ul>
<li>An interaction is present when the simple effects (akin to simple main effect - more below) of one independent variable are not the same at all levels of the second independent variable.</li>
<li>If there in an interaction, main effects are hard to interpret, much more so than with continuous interactions</li>
</ul>

</article></slide><slide class=""><hgroup><h2>how is this similar to a linear model?</h2></hgroup><article  id="how-is-this-similar-to-a-linear-model">

<ul>
<li><p>is this: \[ Y_{ijk} = \mu + \alpha_{j} + \beta_{k} + \alpha \beta_{jk}+\varepsilon_{ijk} \]</p></li>
<li><p>this? \[ Y_{ijk} = b_{0} + b_{1}J + b_{2}K + b_{3}JK + \varepsilon_{ijk} \]</p></li>
</ul>

</article></slide><slide class=""><hgroup><h2>Effect coding a factorial ANOVA</h2></hgroup><article  id="effect-coding-a-factorial-anova">

<ul>
<li>j-1 and k-1 variables for main effects<br/></li>
<li>(j-1)(k-1) variables for interaction<br/><br> \(J_{ij}\) = 1 if in column j, -1 if in last column, 0 for all other columns<br/>\(K_{ik}\) = 1 if in row k, -1 if in last row, 0 for all other rows<br/>\(JK_{i}\) = pairwise product of each J with K variable</li>
</ul>

</article></slide><slide class=""><hgroup><h2>linear model equation</h2></hgroup><article  id="linear-model-equation">

<p>\[ Y_{ijk} = b_{0} + b_{1}J1 + b_{2}K1 + b_{3}K2 + b_{4}J1K1 + b_{5}J1K2 +\varepsilon_{ijk} \]</p>

<table class = 'rmdtable'>
<tr class="header">
<th align="left"></th>
<th align="left"></th>
<th align="left">Factor</th>
<th align="left">A</th>
<th align="left">Marginal Means</th>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left"></td>
<td align="left">Tx</td>
<td align="left">Control</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">B</td>
<td align="left">neutral</td>
<td align="left">7.6</td>
<td align="left">5.0</td>
<td align="left">6.33</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left">sad</td>
<td align="left">8.3</td>
<td align="left">5.0</td>
<td align="left">6.66</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">happy</td>
<td align="left">7.3</td>
<td align="left">8.0</td>
<td align="left">7.66</td>
</tr>
<tr class="odd">
<td align="left">______</td>
<td align="left">_______</td>
<td align="left">______</td>
<td align="left">____________</td>
<td align="left">______________________</td>
</tr>
<tr class="even">
<td align="left">M.M</td>
<td align="left"></td>
<td align="left">7.77</td>
<td align="left">6.0</td>
<td align="left">6.88</td>
</tr>
</table>

</article></slide><slide class=""><hgroup><h2>coding</h2></hgroup><article  id="coding">

<table class = 'rmdtable'>
<tr class="header">
<th align="left">row</th>
<th align="left">column</th>
<th align="left">J1</th>
<th align="left">K1</th>
<th align="left">K2</th>
<th align="left">J1K1</th>
<th align="left">J1K2</th>
</tr>
<tr class="odd">
<td align="left">1</td>
<td align="left">1</td>
<td align="left">1</td>
<td align="left">1</td>
<td align="left">0</td>
<td align="left">1</td>
<td align="left">0</td>
</tr>
<tr class="even">
<td align="left">1</td>
<td align="left">2</td>
<td align="left">-1</td>
<td align="left">1</td>
<td align="left">0</td>
<td align="left">-1</td>
<td align="left">0</td>
</tr>
<tr class="odd">
<td align="left">2</td>
<td align="left">1</td>
<td align="left">1</td>
<td align="left">0</td>
<td align="left">1</td>
<td align="left">0</td>
<td align="left">1</td>
</tr>
<tr class="even">
<td align="left">2</td>
<td align="left">2</td>
<td align="left">-1</td>
<td align="left">0</td>
<td align="left">1</td>
<td align="left">0</td>
<td align="left">-1</td>
</tr>
<tr class="odd">
<td align="left">3</td>
<td align="left">1</td>
<td align="left">1</td>
<td align="left">-1</td>
<td align="left">-1</td>
<td align="left">-1</td>
<td align="left">-1</td>
</tr>
<tr class="even">
<td align="left">3</td>
<td align="left">2</td>
<td align="left">-1</td>
<td align="left">-1</td>
<td align="left">-1</td>
<td align="left">1</td>
<td align="left">1</td>
</tr>
</table>

</article></slide><slide class=""><hgroup><h2>but where is this in our output if ANOVA is regression?</h2></hgroup><article  id="but-where-is-this-in-our-output-if-anova-is-regression">

</article></slide><slide class=""><hgroup><h2>example</h2></hgroup><article  id="example">

<pre class = 'prettyprint lang-r'>data</pre>

<pre >##      id  Anxiety   Stress   group SupportLevel
## 1     2 10.18520  3.19813      Tx          med
## 2     4  5.58873  7.00840 Control          med
## 3     6  6.58500  6.17400      Tx         high
## 4    19  8.95430  8.69884      Tx         high
## 5    40  7.59910  5.26707 Control          med
## 6    45  8.15600  5.12485      Tx          med
## 7    51  9.08020  6.85380      Tx          med
## 8    54  3.41339  1.77080 Control          low
## 9    86  8.65810  3.75282      Tx          med
## 10   92  4.84619  5.44990      Tx         high
## 11  103  5.74215  5.62860      Tx         high
## 12  109  6.30689  0.87730 Control          low
## 13  128 10.62630  6.73299      Tx          med
## 14  129  6.74786  4.43970 Control          med
## 15  137 11.20270  5.92424      Tx          med
## 16  140  4.22281  6.19710 Control         high
## 17  146  4.02796  7.32090      Tx         high
## 18  148 11.52380  6.02653 Control          med
## 19  149  3.06053 10.32460      Tx         high
## 20  150  6.74862  3.77070      Tx         high
## 21  154  3.48494  5.73500      Tx         high
## 22  159 11.69430  5.49516 Control          med
## 23  172  7.51840  3.69930 Control          med
## 24  177  8.22450  4.58931      Tx         high
## 25  199  7.23860  4.85550      Tx         high
## 26  218  7.34928  1.98710 Control          med
## 27  233  5.75941  5.07930      Tx          med
## 28  236  7.00715  6.37110 Control         high
## 29  241 12.38370  6.06967      Tx          med
## 30  242  8.35940  4.85614 Control          med
## 31  245  8.96980  4.22895      Tx         high
## 32  248  1.42272  6.21800      Tx         high
## 33  250  5.92340  2.73780 Control          med
## 34  264  8.93240  5.91872      Tx         high
## 35  277  3.30110  4.61770 Control          med
## 36  278  6.56458  2.36060 Control          med
## 37  281  6.94696  6.28690      Tx         high
## 38  283  9.50410  7.63132 Control          med
## 39  293  3.72717  4.07220      Tx          med
## 40  296 10.42930  5.18795 Control          med
## 41  306  8.92290  4.84015      Tx         high
## 42  308  9.76150  6.09571 Control          med
## 43  311  8.40130  3.79769      Tx          med
## 44  317  8.87070  6.40170 Control          med
## 45  321 12.46200  6.93395 Control          low
## 46  327  5.91552  3.76590 Control          low
## 47  328  1.43546 10.26690      Tx         high
## 48  344  9.91500  5.86156 Control          med
## 49  346  7.55243  7.85160      Tx          med
## 50  366 10.98990  2.41348 Control          med
## 51  373  8.00460  4.77413      Tx          med
## 52  386  8.70800  4.72610 Control          med
## 53  389  6.64578  4.71560      Tx         high
## 54  401  8.26250  5.94780 Control          med
## 55  422  6.83593  4.24490      Tx         high
## 56  427  7.85910  7.06578 Control          med
## 57  429 10.05930  5.73959      Tx          med
## 58  450  7.96930  5.22234 Control          med
## 59  453  7.71770  4.45613      Tx          med
## 60  472 10.79840  4.93474 Control          low
## 61  498  6.30535  1.19090      Tx          low
## 62  500  3.03299  5.74880 Control         high
## 63  503  9.37370  5.39401      Tx          low
## 64  509  9.82540  6.77647 Control          med
## 65  543  5.96415  7.64280      Tx         high
## 66  548  9.77050  6.34933 Control          med
## 67  563  5.91696  5.80840      Tx         high
## 68  572  8.64300  2.51234 Control          med
## 69  581  7.83910  4.92870      Tx          med
## 70  585  6.96872  4.90600 Control         high
## 71  589  6.14228  4.75350      Tx          med
## 72  602  9.96160  2.33024 Control          low
## 73  613  6.07524  6.26700      Tx         high
## 74  620  5.81347  2.38410      Tx          med
## 75  628  5.86049  4.85550      Tx         high
## 76  636  3.69099  6.31990      Tx         high
## 77  638 10.23080  2.06760      Tx          med
## 78  642 14.64280  5.92291 Control          low
## 79  650  5.38190  2.94320 Control          med
## 80  674  8.03270  3.87622 Control          med
## 81  682  5.55689  5.98730      Tx         high
## 82  693  6.15461  6.28450      Tx          med
## 83  699  6.32920  2.92210 Control          med
## 84  705  3.58692  4.14990 Control          med
## 85  720  6.96691  9.27720      Tx         high
## 86  724 10.48390  6.65055 Control          med
## 87  730  8.52930  9.39876      Tx         high
## 88  744  6.56244  5.83090 Control          med
## 89  748  9.04010  5.27865      Tx          med
## 90  750  7.93810  2.18252 Control         high
## 91  754  8.60400  4.66802      Tx          med
## 92  763  7.14036  3.79440 Control         high
## 93  774  8.70630  7.09303      Tx         high
## 94  792  4.36330  3.38110 Control          med
## 95  809  9.99220  5.59351      Tx          med
## 96  811  7.97650  5.58365 Control          med
## 97  814  9.54210  2.99499      Tx          med
## 98  842 11.48600  6.69221 Control          med
## 99  843  8.98960  7.23388      Tx          med
## 100 858  7.50061  3.35810 Control          low
## 101 866  5.48820  5.16900      Tx          med
## 102 883  7.61550  4.06621 Control          med
## 103 886  6.81157  7.22480      Tx         high
## 104 889  7.88520  3.78065 Control          med
## 105 895  8.23370  6.18172      Tx         high
## 106 903 10.11080  5.49338 Control          med
## 107 904  9.63430  5.04774      Tx          med
## 108 914  8.92570  5.66546 Control          med
## 109 924  8.48850  2.29235      Tx          med
## 110 927  7.04304  6.91290 Control         high
## 111 937  7.16339  0.61620      Tx          low
## 112 944  0.69848  9.16670 Control         high
## 113 969  7.78460  3.69495      Tx          med
## 114 978 11.12100  3.65619 Control          low
## 115 981  6.95909  5.39230      Tx          med
## 116 982  5.08169  6.79640 Control         high
## 117 984 13.12260  7.08190      Tx          med
## 118 986  6.29789  3.07360 Control         high</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section">

<pre class = 'prettyprint lang-r'>data %&gt;% 
  select(group, SupportLevel) %&gt;% 
  table()</pre>

<pre >##          SupportLevel
## group     low med high
##   Control   9  37   10
##   Tx        3  30   29</pre>

</article></slide><slide class=""><hgroup><h2>aov function</h2></hgroup><article  id="aov-function">

<pre class = 'prettyprint lang-r'>aov.1 &lt;- aov(Anxiety ~ group + SupportLevel + group*SupportLevel, data=data)
summary(aov.1)</pre>

<pre >##                     Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## group                1    5.4    5.37   1.051    0.307    
## SupportLevel         2  137.7   68.86  13.484 5.66e-06 ***
## group:SupportLevel   2    8.7    4.35   0.851    0.430    
## Residuals          112  572.0    5.11                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</pre>

</article></slide><slide class=""><hgroup><h2>lm anova</h2></hgroup><article  id="lm-anova">

<pre class = 'prettyprint lang-r'>lm.1 &lt;- lm(Anxiety ~ group + SupportLevel + group*SupportLevel, data=data)
anova(lm.1)</pre>

<pre >## Analysis of Variance Table
## 
## Response: Anxiety
##                     Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## group                1   5.37   5.369  1.0514    0.3074    
## SupportLevel         2 137.72  68.861 13.4838 5.663e-06 ***
## group:SupportLevel   2   8.69   4.347  0.8512    0.4296    
## Residuals          112 571.98   5.107                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</pre>

</article></slide><slide class=""><hgroup><h2>lm summary with nominal variables</h2></hgroup><article  id="lm-summary-with-nominal-variables">

<pre >## # A tibble: 6 x 5
##   term                     estimate std.error statistic  p.value
##   &lt;chr&gt;                       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)                 9.12      0.753     12.1  4.30e-22
## 2 groupTx                    -1.51      1.51      -1.00 3.18e- 1
## 3 SupportLevelmed            -0.978     0.840     -1.16 2.47e- 1
## 4 SupportLevelhigh           -3.58      1.04      -3.45 7.93e- 4
## 5 groupTx:SupportLevelmed     1.88      1.61       1.17 2.45e- 1
## 6 groupTx:SupportLevelhigh    2.22      1.72       1.29 1.99e- 1</pre>

<p>\[ Y_{ijk} = b_{0} + b_{1}J1 + b_{2}K1 + b_{3}K2 + b_{4}J1K1 + b_{5}J1K2 +\varepsilon_{ijk} \]</p>

</article></slide><slide class=""><hgroup><h2>But what contrasts did R use?</h2></hgroup><article  id="but-what-contrasts-did-r-use">

<pre class = 'prettyprint lang-r'>contrasts(data$group)</pre>

<pre >##         Tx
## Control  0
## Tx       1</pre>

<pre class = 'prettyprint lang-r'>contrasts(data$SupportLevel)</pre>

<pre >##      med high
## low    0    0
## med    1    0
## high   0    1</pre>

<ul>
<li>we will see why this doesn’t matter</li>
</ul>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-1">

<pre class = 'prettyprint lang-r'>data$group.effect &lt;- data$group
data$SupportLevel.effect &lt;- data$SupportLevel

contrasts(data$group.effect) &lt;- contr.sum(2)
contrasts(data$SupportLevel.effect) &lt;- contr.sum(3)

contrasts(data$group.effect)</pre>

<pre >##         [,1]
## Control    1
## Tx        -1</pre>

<pre class = 'prettyprint lang-r'>contrasts(data$SupportLevel.effect)</pre>

<pre >##      [,1] [,2]
## low     1    0
## med     0    1
## high   -1   -1</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-2">

<pre class = 'prettyprint lang-r'>lm.1.effect &lt;- lm(Anxiety ~ group.effect + SupportLevel.effect + group.effect*SupportLevel.effect, data=data)
tidy(lm.1.effect)</pre>

<pre >## # A tibble: 6 x 5
##   term                               estimate std.error statistic  p.value
##   &lt;chr&gt;                                 &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)                          7.53       0.301    25.0   1.18e-47
## 2 group.effect1                        0.0726     0.301     0.241 8.10e- 1
## 3 SupportLevel.effect1                 0.837      0.529     1.58  1.16e- 1
## 4 SupportLevel.effect2                 0.797      0.341     2.34  2.13e- 2
## 5 group.effect1:SupportLevel.effect1   0.683      0.529     1.29  2.00e- 1
## 6 group.effect1:SupportLevel.effect2  -0.255      0.341    -0.748 4.56e- 1</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-3">

<pre class = 'prettyprint lang-r'>anova(lm.1.effect)</pre>

<pre >## Analysis of Variance Table
## 
## Response: Anxiety
##                                   Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## group.effect                       1   5.37   5.369  1.0514    0.3074    
## SupportLevel.effect                2 137.72  68.861 13.4838 5.663e-06 ***
## group.effect:SupportLevel.effect   2   8.69   4.347  0.8512    0.4296    
## Residuals                        112 571.98   5.107                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-4">

<pre class = 'prettyprint lang-r'>anova(lm.1)</pre>

<pre >## Analysis of Variance Table
## 
## Response: Anxiety
##                     Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## group                1   5.37   5.369  1.0514    0.3074    
## SupportLevel         2 137.72  68.861 13.4838 5.663e-06 ***
## group:SupportLevel   2   8.69   4.347  0.8512    0.4296    
## Residuals          112 571.98   5.107                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</pre>

</article></slide><slide class=""><hgroup><h2>Interpretting interactions</h2></hgroup><article  id="interpretting-interactions">

<ul>
<li>beyond noticing whether cell means look different we can do formal tests<br/></li>
<li>~3 types</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Interpretting interactions part 2</h2></hgroup><article  id="interpretting-interactions-part-2">

<p>’1. Is the interaction significant? If not, this helps interpret our main effects. If it is, we can graph and interpret or also do additional tets.</p>

<pre class = 'prettyprint lang-r'>aov.1 &lt;- aov(Anxiety ~ group + SupportLevel + group*SupportLevel, data=data)
aov.0 &lt;- aov(Anxiety ~ group + SupportLevel, data=data)

anova(aov.0, aov.1)</pre>

<pre >## Analysis of Variance Table
## 
## Model 1: Anxiety ~ group + SupportLevel
## Model 2: Anxiety ~ group + SupportLevel + group * SupportLevel
##   Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)
## 1    114 580.68                           
## 2    112 571.98  2    8.6946 0.8512 0.4296</pre>

</article></slide><slide class=""><hgroup><h2>Interpretting interactions part 2</h2></hgroup><article  id="interpretting-interactions-part-2-1">

<p>’2. regression coefficients</p>

<p>\[ Y_{ijk} = b_{0} + b_{1}J1 + b_{2}K1 + b_{3}K2 + b_{4}J1K1 + b_{5}J1K2 +\varepsilon_{ijk} \] - Remember, this is likely done with default dummy - Typically not used as you are likely interested in more than just a few comparisons - Same is true even if we use effect coding</p>

</article></slide><slide class=""><hgroup><h2>Interpretting interactions part 2</h2></hgroup><article  id="interpretting-interactions-part-2-2">

<p>’3. Planned contrasts/Post hoc comparisons/simple main effects</p>

<ul>
<li>All of these fall under the rubric of &lsquo;contrasts&rsquo;<br/></li>
<li>The most basic of these is Tukey honestly significant difference</li>
<li>Note: TukeyHSD function requires aov model not lm</li>
</ul>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-5">

<pre class = 'prettyprint lang-r'>TukeyHSD(aov.1)</pre>

<pre >##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = Anxiety ~ group + SupportLevel + group * SupportLevel, data = data)
## 
## $group
##                 diff       lwr       upr     p adj
## Tx-Control -0.427179 -1.252644 0.3982863 0.3074021
## 
## $SupportLevel
##                diff       lwr        upr     p adj
## med-low  -0.3527543 -2.035355  1.3298467 0.8724259
## high-low -2.4652166 -4.237192 -0.6932408 0.0036321
## high-med -2.1124623 -3.193595 -1.0313300 0.0000281
## 
## $`group:SupportLevel`
##                                diff       lwr        upr     p adj
## Tx:low-Control:low       -1.5105433 -5.879098  2.8580117 0.9161763
## Control:med-Control:low  -0.9782492 -3.413737  1.4572381 0.8525525
## Tx:med-Control:low       -0.6133680 -3.103828  1.8770916 0.9798772
## Control:high-Control:low -3.5815670 -6.592386 -0.5707482 0.0100559
## Tx:high-Control:low      -2.8716817 -5.372031 -0.3713328 0.0145676
## Control:med-Tx:low        0.5322941 -3.401373  4.4659610 0.9987682
## Tx:med-Tx:low             0.8971753 -3.070762  4.8651125 0.9862766
## Control:high-Tx:low      -2.0710237 -6.384626  2.2425788 0.7316435
## Tx:high-Tx:low           -1.3611384 -5.335290  2.6130133 0.9192628
## Tx:med-Control:med        0.3648812 -1.245041  1.9748037 0.9861282
## Control:high-Control:med -2.6033178 -4.938803 -0.2678325 0.0195879
## Tx:high-Control:med      -1.8934325 -3.518611 -0.2682536 0.0125644
## Control:high-Tx:med      -2.9681990 -5.360955 -0.5754428 0.0062447
## Tx:high-Tx:med           -2.2583137 -3.964771 -0.5518563 0.0027702
## Tx:high-Control:high      0.7098853 -1.693162  3.1129329 0.9558328</pre>

</article></slide><slide class=""><hgroup><h2>post hoc tests</h2></hgroup><article  id="post-hoc-tests">

<ul>
<li><p>Mainly adjust error rates for multiple comparisons</p></li>
<li>Planned contrasts, a priori: Holm, Dunn-Bonnferoni, perhaps Tukey</li>
<li>All pairwise comparisons (maybe a priori): Tukey</li>
<li><p>Post hoc fishing: Scheffe, perhaps Tukey if you can sleep at nigh</p></li>
</ul>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-6">

<pre class = 'prettyprint lang-r'># library(lsmeans) outdated, but code still works
library(emmeans) ## new and shiny
em.1&lt;- emmeans(lm.1, c(&quot;group&quot;, &quot;SupportLevel&quot;))
# can be used to test numerous a prior and post hoc hypotheses
# can use both lm and aov models (and more!)
# estimated means especially important for graphing
# see more here: 
#https://cran.r-project.org/web/packages/emmeans/vignettes/basics.html</pre>

<h4>Quick plot</h4>

<pre class = 'prettyprint lang-r'>emmip(aov.1, group ~ SupportLevel)</pre>

<p><img src="anova-8_files/figure-html/unnamed-chunk-15-1.png" width="720" /></p>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-7">

<pre class = 'prettyprint lang-r'>em.1</pre>

<pre >##  group   SupportLevel emmean    SE  df lower.CL upper.CL
##  Control low            9.12 0.753 112     7.63    10.62
##  Tx      low            7.61 1.305 112     5.03    10.20
##  Control med            8.15 0.372 112     7.41     8.88
##  Tx      med            8.51 0.413 112     7.69     9.33
##  Control high           5.54 0.715 112     4.13     6.96
##  Tx      high           6.25 0.420 112     5.42     7.08
## 
## Confidence level used: 0.95</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-8">

<pre class = 'prettyprint lang-r'>emmeans(em.1, specs = &quot;group&quot;)</pre>

<pre >## NOTE: Results may be misleading due to involvement in interactions</pre>

<pre >##  group   emmean    SE  df lower.CL upper.CL
##  Control   7.60 0.368 112     6.88     8.33
##  Tx        7.46 0.477 112     6.51     8.40
## 
## Results are averaged over the levels of: SupportLevel 
## Confidence level used: 0.95</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-9">

<pre class = 'prettyprint lang-r'>emmeans(aov.1, pairwise ~ group)</pre>

<pre >## NOTE: Results may be misleading due to involvement in interactions</pre>

<pre >## $emmeans
##  group   emmean    SE  df lower.CL upper.CL
##  Control   7.60 0.368 112     6.88     8.33
##  Tx        7.46 0.477 112     6.51     8.40
## 
## Results are averaged over the levels of: SupportLevel 
## Confidence level used: 0.95 
## 
## $contrasts
##  contrast     estimate    SE  df t.ratio p.value
##  Control - Tx    0.145 0.602 112 0.241   0.8099 
## 
## Results are averaged over the levels of: SupportLevel</pre>

<pre class = 'prettyprint lang-r'>emmeans(aov.1, pairwise ~ SupportLevel)</pre>

<pre >## NOTE: Results may be misleading due to involvement in interactions</pre>

<pre >## $emmeans
##  SupportLevel emmean    SE  df lower.CL upper.CL
##  low            8.37 0.753 112     6.88     9.86
##  med            8.33 0.278 112     7.78     8.88
##  high           5.90 0.414 112     5.08     6.72
## 
## Results are averaged over the levels of: group 
## Confidence level used: 0.95 
## 
## $contrasts
##  contrast   estimate    SE  df t.ratio p.value
##  low - med    0.0405 0.803 112 0.050   0.9986 
##  low - high   2.4714 0.860 112 2.875   0.0133 
##  med - high   2.4308 0.499 112 4.874   &lt;.0001 
## 
## Results are averaged over the levels of: group 
## P value adjustment: tukey method for comparing a family of 3 estimates</pre>

</article></slide><slide class=""><hgroup><h2>emmeans can also do tukey (and other adjustments)</h2></hgroup><article  id="emmeans-can-also-do-tukey-and-other-adjustments">

<pre class = 'prettyprint lang-r'>pairs(em.1, adjust = &quot;tukey&quot;)</pre>

<pre >##  contrast                   estimate    SE  df t.ratio p.value
##  Control,low - Tx,low          1.511 1.507 112  1.003  0.9162 
##  Control,low - Control,med     0.978 0.840 112  1.165  0.8526 
##  Control,low - Tx,med          0.613 0.859 112  0.714  0.9799 
##  Control,low - Control,high    3.582 1.038 112  3.449  0.0101 
##  Control,low - Tx,high         2.872 0.862 112  3.330  0.0146 
##  Tx,low - Control,med         -0.532 1.357 112 -0.392  0.9988 
##  Tx,low - Tx,med              -0.897 1.368 112 -0.656  0.9863 
##  Tx,low - Control,high         2.071 1.488 112  1.392  0.7316 
##  Tx,low - Tx,high              1.361 1.371 112  0.993  0.9193 
##  Control,med - Tx,med         -0.365 0.555 112 -0.657  0.9861 
##  Control,med - Control,high    2.603 0.805 112  3.232  0.0196 
##  Control,med - Tx,high         1.893 0.560 112  3.378  0.0126 
##  Tx,med - Control,high         2.968 0.825 112  3.597  0.0062 
##  Tx,med - Tx,high              2.258 0.589 112  3.837  0.0028 
##  Control,high - Tx,high       -0.710 0.829 112 -0.857  0.9558 
## 
## P value adjustment: tukey method for comparing a family of 6 estimates</pre>

<pre class = 'prettyprint lang-r'># try &quot;holm&quot; and &quot;bon&quot;</pre>

</article></slide><slide class=""><hgroup><h2>post hoc tests</h2></hgroup><article  id="post-hoc-tests-1">

<pre class = 'prettyprint lang-r'># can use contrast function to get equivalent to pairs function 
#contrast(em.1, method = &quot;pairwise&quot;)
#or look at effects rather than pairwise
contrast(em.1, method = &quot;eff&quot;)</pre>

<pre >##  contrast            estimate    SE  df t.ratio p.value
##  Control,low effect     1.593 0.685 112  2.326  0.0437 
##  Tx,low effect          0.082 1.107 112  0.074  0.9411 
##  Control,med effect     0.614 0.427 112  1.437  0.1841 
##  Tx,med effect          0.979 0.452 112  2.167  0.0485 
##  Control,high effect   -1.989 0.657 112 -3.029  0.0179 
##  Tx,high effect        -1.279 0.456 112 -2.804  0.0179 
## 
## P value adjustment: fdr method for 6 tests</pre>

</article></slide><slide class=""><hgroup><h2>simple main effects</h2></hgroup><article  id="simple-main-effects">

<pre class = 'prettyprint lang-r'>joint_tests(aov.1, by = &quot;SupportLevel&quot;)</pre>

<pre >## SupportLevel = low:
##  model term df1 df2 F.ratio p.value
##  group        1 112   1.005 0.3182 
## 
## SupportLevel = med:
##  model term df1 df2 F.ratio p.value
##  group        1 112   0.432 0.5124 
## 
## SupportLevel = high:
##  model term df1 df2 F.ratio p.value
##  group        1 112   0.734 0.3935</pre>

</article></slide><slide class=""><hgroup><h2>more post hoc tests</h2></hgroup><article  id="more-post-hoc-tests">

<pre class = 'prettyprint lang-r'>#library(multcomp)
# multcomp::glht(aov.1)

# Nice package that allows you to do many of the same functions as 
# emmeans but it has one major downside: MASS is loaded and 
# thus masks dplyr::select</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-10">

<pre class = 'prettyprint lang-r'>library(phia)
testInteractions(aov.1, pairwise=&quot;SupportLevel&quot;)</pre>

<pre >## F Test: 
## P-value adjustment method: holm
##             Value  Df Sum of Sq       F    Pr(&gt;F)    
##  low-med  0.04054   1      0.01  0.0025  0.959819    
## low-high  2.47135   1     42.20  8.2631  0.009686 ** 
## med-high  2.43082   1    121.31 23.7528 1.091e-05 ***
## Residuals         112    571.98                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-11">

<pre class = 'prettyprint lang-r'>testInteractions(aov.1, pairwise=&quot;group&quot;)</pre>

<pre >## F Test: 
## P-value adjustment method: holm
##              Value  Df Sum of Sq      F Pr(&gt;F)
## Control-Tx 0.14526   1      0.30 0.0582 0.8099
## Residuals          112    571.98</pre>

</article></slide><slide class=""><hgroup><h2>different types of Sums of Squares</h2></hgroup><article  id="different-types-of-sums-of-squares">

<ul>
<li>3 types, 3 different hypotheses testing strategies<br/></li>
<li>Type 1, hierarchical (what R does)<br/></li>
<li>Type 3, simultaneous<br/></li>
<li>Type 2, looks at higher- versus lower-order<br/><br><br/></li>
<li>SSwithin and SSinteraction will be same, regardless<br/></li>
<li>All about how we want to interpret main effects (which we often don’t)</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Type 1: Hierarchical (what R does)</h2></hgroup><article  id="type-1-hierarchical-what-r-does">

<ul>
<li>Think of it as model comparisons. You always have to compare to something<br/>A: anova(null, Factor A)<br/>B: anova(Factor A, FactorA+B)<br/>AB: anova(FactorA+B, FactorA+B+A*B)<br/></li>
<li>SS is just like our partial correlation calculation for R2 when adding terms to hierarchical regression</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Type 3: Controls for all predictors</h2></hgroup><article  id="type-3-controls-for-all-predictors">

<p>A: anova(Factor B+A<em>B, FactorA+B+A</em>B)<br/>B: anova(Factor A+A<em>B, FactorA+B+A</em>B)<br/>AB: anova(FactorA+B, FactorA+B+A*B)</p>

<ul>
<li>Most common, most recommended<br/></li>
<li>Still strange, in that it tests higher order term without a lower order term in the model<br/></li>
<li>Use Anova function from car package</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Type 2: Not popular</h2></hgroup><article  id="type-2-not-popular">

<p>A: anova(Factor B, FactorA+B)<br/>B: anova(Factor A, FactorA+B)<br/>AB: anova(FactorA+B, FactorA+B+A*B)</p>

<ul>
<li>Need to use car::Anova function<br/></li>
<li>Most interpretable, in my opinion.</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Effect sizes</h2></hgroup><article  id="effect-sizes">

<ul>
<li>Eta squared is like R squared for an effect SS effect / SS total<br/><br></li>
<li>Partial eta squared (SS effect / (SS effect + SS resid))<br/></li>
<li>the variance explained by a given variable of the variance remaining explained by other predictors<br/></li>
<li>Partial will always be larger, but not interpretable with sig interaction</li>
</ul>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-12">

<pre class = 'prettyprint lang-r'>library(lsr)
etaSquared(aov.1)</pre>

<pre >##                         eta.sq eta.sq.part
## group              0.003305332 0.004165048
## SupportLevel       0.190285765 0.194056573
## group:SupportLevel 0.012012944 0.014973213</pre>

</article></slide><slide class=""><hgroup><h2>Don’t forget omega squared and cohen’s f</h2></hgroup><article  id="dont-forget-omega-squared-and-cohens-f">

<ul>
<li>Better than eta, adjusts for bias</li>
<li>Omega Squared is always smaller than Eta Squared.<br/></li>
<li>see: <a href='http://daniellakens.blogspot.com/2015/06/why-you-should-use-omega-squared.html' title=''>http://daniellakens.blogspot.com/2015/06/why-you-should-use-omega-squared.html</a><br/></li>
<li>cohen’s f is used in pwr but it isn’t popular or intuitive</li>
</ul>

</article></slide><slide class=""><hgroup><h2>ANCOVA</h2></hgroup><article  id="ancova">

<ul>
<li>ANalysis of COVAriance</li>
<li>aka regression with continuous and nominal variables</li>
<li>given a special name because of historical reasons</li>
<li>Typically, when someone says they are doing an ANCOVA they are focused on comparing group means adjusted for some covariate</li>
</ul>

</article></slide><slide class=""><hgroup><h2>ANCOVA</h2></hgroup><article  id="ancova-1">

<p>\[ \hat{Y} = b_{0} + b_{1}D_{1} + b_{2}D_{2} + b_{3}GPA  \] - how do you interpret each term? - what does this look like graphed? - Would b1 and b2 change if we ran a model without GPA?</p>

</article></slide><slide class=""><hgroup><h2>2 advantages of ANCOVA</h2></hgroup><article  id="advantages-of-ancova">

<ol>
<li>Greater power</li>
<li>Adjustment of/controlling for covariate</li>
</ol>

</article></slide><slide class=""><hgroup><h2>ANCOVA power advantages</h2></hgroup><article  id="ancova-power-advantages">

<ul>
<li>what is SS residual?</li>
<li>how is it used to test your model?</li>
<li>how can you decrease SS residual?</li>
</ul>

</article></slide><slide class=""><hgroup><h2>ANCOVA power advantages</h2></hgroup><article  id="ancova-power-advantages-1">

<ul>
<li>power does not necessarily incrase if covariate is related to the predictor (e.g., group). Why?</li>
<li>how do you find groups not related to the covariate?</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Controlling for background covariates</h2></hgroup><article  id="controlling-for-background-covariates">

<ul>
<li>in experimental designs, power should be main focus</li>
<li>in quasi-experimental designs, covariates should help &ldquo;equate&rdquo; groups</li>
</ul>

<p>\[ \hat{Y} = b_{0} + b_{1}D_{1} + b_{2}D_{2} + b_{3}GPA  \]</p>

<ul>
<li>note: you are now making a different prediction for each individual, rather than having the same prediction for all group members</li>
<li>likely also reduces SS residual</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Controlling for background covariates</h2></hgroup><article  id="controlling-for-background-covariates-1">

<ul>
<li>controlling for is not a panacea</li>
<li>does not fix issues when random assigment is ineffective</li>
<li>could create greater group difference, no difference or even reverse the difference</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Standard ANCOVA assumes no interactions; regression association is the same across groups</h2></hgroup><article  id="standard-ancova-assumes-no-interactions-regression-association-is-the-same-across-groups">

<p>\[ \hat{Y} = b_{0} + b_{1}D_{1} + b_{2}D_{2} + b_{3}GPA  \]</p>

<p>\[ \hat{Y} = b_{0} + b_{1}D_{1} + b_{2}D_{2} + b_{3}GPA + b_{4}(D_{1} * GPA) + b_{5}(D_{2} * GPA)  \]</p>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-13">

<pre class = 'prettyprint lang-r'>aov.2 &lt;- aov(Anxiety ~ group + SupportLevel + group*SupportLevel + Stress, data=data)
summary(aov.2)</pre>

<pre >##                     Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## group                1    5.4    5.37   1.063   0.3048    
## SupportLevel         2  137.7   68.86  13.630 5.09e-06 ***
## Stress               1   14.0   14.00   2.771   0.0988 .  
## group:SupportLevel   2    5.9    2.93   0.580   0.5614    
## Residuals          111  560.8    5.05                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-14">

<pre class = 'prettyprint lang-r'>summary(aov.1)</pre>

<pre >##                     Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## group                1    5.4    5.37   1.051    0.307    
## SupportLevel         2  137.7   68.86  13.484 5.66e-06 ***
## group:SupportLevel   2    8.7    4.35   0.851    0.430    
## Residuals          112  572.0    5.11                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-15">

<pre class = 'prettyprint lang-r'>em.2&lt;- emmeans(aov.2, c(&quot;group&quot;, &quot;SupportLevel&quot;))
em.2</pre>

<pre >##  group   SupportLevel emmean    SE  df lower.CL upper.CL
##  Control low            9.40 0.771 111     7.87    10.92
##  Tx      low            8.13 1.344 111     5.47    10.79
##  Control med            8.20 0.371 111     7.46     8.93
##  Tx      med            8.56 0.411 111     7.74     9.37
##  Control high           5.48 0.712 111     4.07     6.89
##  Tx      high           6.03 0.444 111     5.15     6.91
## 
## Confidence level used: 0.95</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-16">

<pre class = 'prettyprint lang-r'>em.1</pre>

<pre >##  group   SupportLevel emmean    SE  df lower.CL upper.CL
##  Control low            9.12 0.753 112     7.63    10.62
##  Tx      low            7.61 1.305 112     5.03    10.20
##  Control med            8.15 0.372 112     7.41     8.88
##  Tx      med            8.51 0.413 112     7.69     9.33
##  Control high           5.54 0.715 112     4.13     6.96
##  Tx      high           6.25 0.420 112     5.42     7.08
## 
## Confidence level used: 0.95</pre></article></slide>


  <slide class="backdrop"></slide>

</slides>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!-- map slide visiblity events into shiny -->
<script>
  (function() {
    if (window.jQuery) {
       window.jQuery(document).on('slideleave', function(e) {
         window.jQuery(e.target).trigger('hidden');
      });
       window.jQuery(document).on('slideenter', function(e) {
         window.jQuery(e.target).trigger('shown');
      });
    }
  })();
</script>

</body>
</html>
