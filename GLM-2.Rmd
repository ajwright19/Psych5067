---
title: "GLM"
output: ioslides_presentation
---

## Models

- Thus far you have used t-tests and ANOVA to test basic questions about the world. 
- These types of test can be thought of as a model of the "way the world works"
- Our DV (hereforth Y) is what we are trying to understand
- We hypothesize it has some relationship with your IV(s) (hereforth Xs)  

- Y = X

## See this in our R code

Independent samples t-test
```{r, eval=FALSE}

t.1 <- t.test(y ~ x, data = d) 
# y is cont and x is a categoriocal (dichotomous) factor
```

One-way ANOVA
```{r, eval = FALSE}
a.1 <- aov(y ~ x, data=d)
# y is cont and x is a categoriocal factor

```

## General linear model

- What we are trying to understand is due to how we think the world works  
- This model (equation) can be very simple as in a treatment/control experiment  
- It can be very complex in terms of trying to understand something like academic achievment  
- The majority of our models fall under the umbrella of a general(ized) linear model 


## Regression Equation

$$ Y = b_{0} + b_{1}X +e  $$

$$ \hat{Y} = b_{0} + b_{1}X  $$

$$ \mu_{Y} = \beta_{0} + \beta_{1}X + \epsilon   $$

$$Y = X\beta + U$$

## Regression terms
- Y/DV/Outcome/Response/Criterion
- X/IV/Predictor/Explanatory variable
- Regression coeffiecent (weight)/b/b*/$\beta$
- Intercept bo/$\beta_{0}$
- Error/Residuals $e$
- Predictions$\hat{Y}$


## Example
```{r, echo = FALSE, messages = FALSE, warnings = FALSE}
library(tidyverse)

example.data <- read.csv("example.data.csv")

```

- Get this data at my github account: https://github.com/josh-jackson/Psych5067
```{r}
example.data
```
##

```{r, warning=FALSE}
ggplot(example.data) +
  aes(x = as.factor(tx), y = traffic.risk) +
  geom_violin() + geom_boxplot()
```

## example
```{r}
t.1 <- t.test(traffic.risk ~ tx, data = example.data, var.equal = TRUE) 
t.1

```

## example
```{r}
a.1 <- aov(traffic.risk ~ tx, data = example.data) 
summary(a.1)
```

## example

```{r}
mod.1 <- lm(traffic.risk ~ tx, data = example.data)
summary(mod.1)
```

## example
```{r}
mod.1 <- lm(traffic.risk ~ tx, data = example.data)
anova(mod.1)
```

## ANOVA as regression

$$ Y_i = b_{0} + b_{1}X_i + e_i  $$
$$ T.risk_i = b_{0} + b_{1}TX_i + e_i  $$

- Each individual has a unique Y value an X value and a residual/error term  

- The model only has a single $b_{0}$ and $b_{1}$ term. These are the regression parameters. $b_{0}$ is the intercept and $b_{1}$ quantifies the relationship between your model of the world and the DV. 

## estimates

```{r, echo = FALSE}
library(broom)
tidy(mod.1)
```


## 


```{r}
example.data %>% 
  group_by(tx) %>% 
  summarise(mean(traffic.risk, na.rm=TRUE))
```



## ANOVA as regression

$$ Y_i = b_{0} + b_{1}X_i + e_i  $$

```{r, echo =FALSE}
example.data
```

## 
```{r}
library(dplyr)
example.data$tx.r <- as.factor(example.data$tx)
example.data$tx.r <- recode_factor(example.data$tx.r, "0" = "control", "1" = "treatment") 
```

```{r}
example.data
```


##

```{r}
class(example.data$tx)
```

```{r}
class(example.data$tx.r)
```

- Do you find issues or differences if you use tx vs tx.r? 

- What about if you did this: 
```{r}
example.data$tx.n <- as.numeric(example.data$tx)
class(example.data$tx.n)
```


## what about if you had different values other than 0 and 1? 

- Infinite number of ways to code categorical variables, only a few meaningful ways  
- The R default is called "dummy coding"  
- Uses 0s and 1s to put numbers to categories
- Changing the numbers changes...?


## Effect coding
```{r}
example.data$tx.effect <- dplyr::recode(example.data$tx.n, "0" = -1, "1" = 1) 
```

```{r}
example.data
```


## effect coding

```{r}
mod.1.eff <- lm(traffic.risk ~ tx.effect, data = example.data)
tidy(mod.1.eff)
```
- systematically changes both the intercept and the regression estimate


## Interpretations

```{r, echo = FALSE}
effect <- tidy(mod.1.eff)
effect
dummy <- tidy(mod.1)
dummy
```
- Intercept: value when your predictor (model, X, IV, etc) is zero

- Regression coefficent: one unit increase in X is associated with a (regression estimate) increase in Y

## Effect coding
Consists of -1, 1s (And zeros for more than 2 groups)

1. The intercept is the "grand mean" or "mean of means" if unbalanced
2. The regression coefficient represents the group "effect" ie the difference from the grand mean for the group labeled 1 (we will revisit this when we have more than 2 groups as it will make more sense)

- Common to use for ANOVA models b/c ANOVA models are usually specified this way

## Effect coding

1. The intercept is the "grand mean" or "mean of means" if unbalanced
2. The regression coefficient represens the group "effect" ie the difference from the grand mean

- Common to use for ANOVA models b/c ANOVA models are usually specified this way

- How do you calculate the predicted value of each group? 

## Effect coding

Thought Qs: 

- What happens if you code the groups -.5 and .5? 
- What are the pros and potential cons in this type of coding? 

## Dummy coding
- More appropriate when you are interested in comparing to a specific group rather than an "average person"  

- Intercept: value of the group coded zero 
- Regression coefficient: difference between groups (in mean)

- How do you calculate the predicted value of each group? 


## Intermission

![](intermission.gif)


## Statistical Inference
- The way the world is = our model + error
- How good is our model? Does it "fit" the data well? 
- Need to go beyond asking if it is significant, because what does that mean? 
- We are going to make predictions and see if the predictions (based on our model) matches our data

## Predictions
- predictions $\hat{Y}$ are of the form of E(Y|X)
- They are created by simpling plugging a persons Xs into the created model
- If you have bs and have Xs you can create a prediction

$\hat{Y}_{i}$ = 2.6506410 + -0.4811057*$X_{i}$

## Predictions
- We want our predictions to be close to our actual data (Y)
- The difference between the actual data and our our prediction($ Y_{i}  - \hat{Y}_{i} = e $) is the residual, how far we are "off"


## lm objects

```{r, eval=FALSE}
coefficients(mod.1)       # coefficients
residuals(mod.1)          # residuals
fitted.values(mod.1)      # fitted values ie predicted
summary(mod.1)$r.squared  # R-sq for the model
summary(mod.1)$sigma      # se of the model
```

##
```{r}
coefficients(mod.1)
```


## 
```{r}
fitted.values(mod.1)
```
## 

```{r}
residuals(mod.1)
```


##
```{r}
example.data
```

## pop quiz, hotshot

$$ \hat{Y}_{i} = b_{0} + b_{1}X_{i}  $$

$$ Y_{i} = b_{0} + b_{1}X_{i} +e_{i}  $$
$$ Y_{i}  - \hat{Y}_{i} = e $$

- can you plug in numbers and calculate subject 3's predicted and residual scores without using lm object data? 

## residuals
```{r, echo=FALSE, warnings=FALSE, message=FALSE, include = FALSE}
fit.1.data <- augment(mod.1) 

```

```{r}
ggplot(fit.1.data, aes(.resid)) +
    geom_density()    
   
```


## an aside concerning lm objects
lm objects consist of the information embeded in your linear model (ie mod.1). You use this information to get summary(mod.1) or anova(mod.1) as well as additional pieces of information. R handles model objects poorly because you cannot do advanced manipulation with any of this extra information due to them not being in a data frame.

```{r}
library(broom)
fit.1.tidy <- tidy(mod.1) #tidy turns the summary into a dataframe 
fit.1.tidy
```

##
- Augment ammends the original dataset with lm object content. The new variable names of have a "."" infront of the name to distinguish
```{r, warning=FALSE}
fit.1.data <- augment(mod.1) 
head(fit.1.data)

```

## pop quiz, hotshot, part deux 
- how many different types of predicted values will we have? residuals? 


## Statistical Inference
- In making predictions, we have to compare our prediction to some alternative prediction to see if we are doing well or not. 

- What is our best guess (ie prediction) if we didn't collect any data? 

$$ \hat{Y} = \bar{Y} $$
- E(Y|X)

## Statistical Inference
- To the extent that we can generate different predicted values of Y based on the values of the predictors, our model is doing well

- E(Y|X)

- Said differently, the closer our model is to the "actual" data generating model, our guesses (Y-hats) will be closer to our actual data (Ys)  

## Partitioning variation in Y into 3 components

- We formally test how well we are doing with our guesses by partitioning variation

$$ Y = \hat{Y} + e$$

$$ Y = \hat{Y} + (Y - \hat{Y}) $$

$$ Y - \bar{Y} = (\hat{Y} -\bar{Y}) + (Y - \hat{Y}) $$

$$ (Y - \bar{Y})^2 = [(\hat{Y} -\bar{Y}) + (Y - \hat{Y})]^2 $$

$$ \sum (Y - \bar{Y})^2 = \sum (\hat{Y} -\bar{Y})^2 + \sum(Y - \hat{Y})^2 $$

## Partitioning the variation in Y
$$ \sum (Y - \bar{Y})^2 = \sum (\hat{Y} -\bar{Y})^2 + \sum(Y - \hat{Y})^2 $$

- SS total = SS between + SS within

- SS total = SS regression + SS residual (or error)


## What can we do with this? 

- Last semester you did omnibus F tests
- What hypothesis does the omnibus F test, generally? 

$$ s_{y}^2 = s_{regression}^2 + s_{residual}^2 $$

$$ 1 = \frac{s_{regression}^2}{s_{y}^2} + \frac{s_{residual}^2}{s_{y}^2}  $$


## Coefficient of Determination

$$ \frac{s_{regression}^2}{s_{y}^2} = \frac{SS_{regression}}{SS_{Y}} = R^2 $$

- percent (of total) variance explained by your model

## R squared and Eta squared

```{r}
summary(mod.1)$r.squared
```


```{r}
library(lsr)
etaSquared(mod.1)
```

## R squared

```{r}
tidy(anova(mod.1))
```

```{r}
tidy(anova(mod.1.eff))
```

