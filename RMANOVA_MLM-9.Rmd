---
title: "Repeated measures & MLM"
output: ioslides_presentation
---
## Expanding our toolkit
- We might want to assess people more than once 
- We might want to assess within groups/nested structures 

## Outline
- Repeated Measures ANOVA (RM ANOVA)
- "Mixed" models aka Multilevel models (MLM), hierarchical linear models (HLM), random-effects models, and more...

## Repeated measures ANOVA
- one-way RMANOVA (within subjects ANOVA)
- can also do a mixed designs (both between and within) sometimes refered to as split-plot

## terminology aside
- SS between-groups and SS within-groups 
- between-subjects and within-subjects designs

## why would we want to do this? 

1. our primary interest may be to study the change of an outcome over time, e.g., a learning effect. 
2. multiple outcomes for each subject allows each subject to be his or her own “control”. This allows us to remove subject-to-subject variation (i.e., individidual differences), and likely increasing power 
<br>
<br>
- When would we *not* want to do this? 

## one way RM ANOVA
- extension of the paired t-test  
- E.g. 
    + A measure before, during and after a intervention  
    + A measure repeated across multiple conditions such as condition A, condition B, and condition C
    + Three or more timepoints (seconds, years, grades)
  
## traditional way (univariate) vs "new" way (multivariate)

- different ways to overcome violation of independence
- rabbit hole of complexity that is mostly not worth it...
- because there are newer and better methods
- nevertheless, let us persist 
  
## SS decomposition
- SS between: Deviation of subjects' individual means (across treatments) from the grand mean.
- In the RMANOVA, this is largely uninteresting, as we can pretty much assume that ‘subjects differ’

##

| ID   |wine #1|  #2  | #3  |  #4 | Mean | 
|------|-------|------|-----|-----|------|
| 1    |  2    |  5   |  3  |  3  | 3.25 |  
| 2    |  4    |  6   |  5  |  4  | 4.75 |  
| 3    |  5    |  7   |  4  |  5  | 5.25 |   
| 4    |  3    |  4   |  3  |  4  | 3.5  |  
| 5    |  6    |  7   |  6  |  5  | 6.0  |  
| 6    |  2    |  5   |  4  |  3  | 3.5  |   
| 7    |  4    |  5   |  6  |  4  | 4.75 |
| mean | 3.63  | 5.63 | 4.38| 4.25|      |

## SS decomposition
- SS within: how subjects vary about their own mean 
- Compared to between subjects ANOVA, SS residual (within) is split into 2 different components:
-  SStreatment  
    + As in between subjects ANOVA, comparison of treatment marignal means to grand mean
    + now a part of the within subjects variation
- SS residual  
    + Variability of individuals’ scores about their treatment mean
    + SS residual still is our measure of leftover error variance
  + Smaller error term compared to between subjects 

## post hoc tests
- If the overall ANOVA yields a significant result one can test:  
     + pair-wise comparisons  
     + linear, quadratic trends  

## more complex RM designs
- involve interactions
- involve between person (and/or more within person) variables
- involve multiple SS residual terms

## Interactions

$$ Y_{ijk} = \mu + \eta_{j} + \alpha_{k} + \eta \alpha_{jk}+\varepsilon_{ijk} $$

- The interaction variance contributes to both subjects and A factor SSs
- Decreased power (interaction adds noise to error term)
- May increase sphericity

## Mixed designs

- Between and within factor  
<br>
- Wine tasting by groups (sophomores, sommeliers, souses)  
  + Are some wines rated better? (within)  
  + Do groups rate wine differently (between)  
  + Do sommeliers especially dislike merlot? (within- between subjects interaction)  
- Interactions are now interpretable 

## Problems with RM ANOVA
The sphericity assumption (also known as the homogeneity of variance of differences assumption) assumes the variance of the  differences between any two levels of a within subjects factor (e.g,. condition, time) is equivalent

- Greenhouse-Geisser Epsilon,
 Huynh-Feldt Epsil,
 Pillai’s Trace,
 Wilk’s Lambda,
 Hotelling’s Trace, and
 Roy’s Largest Root

- adjusts df if violated
- but unlikely to find this with observational data

## Problems with RM ANOVA
- complete data, no missing cases (unless you do RM MANOVA)
- spacing is same for all time points (and subjects)
- does not handle continuous data 
- cannot do time varying covariates
- no individaul level trends

## which is why you should use
- MLM, HLM, mixed models, mixed effects, random effects models, etc. 

## Nesting and heirarchy
- students within schools
- observations within people 
- members witin family
- people within counties
- observations within people within classrooms within grades within schools within districts within counties within states
<br>
- ignoring this grouping leads to more unexplained variablity
- innacurate comparisons (e.g. simpson's paradox)

## Example
```{r, message = FALSE}
library(tidyverse)

simp<- frame_data(
  ~ID, ~group,  ~test.score, ~study,
1,1,5,1,
2,1,7,3,
3,2,4,1,
4,2,6,4,
5,3,3,3,
6,3,5,5,
7,4,2,4,
8,4,4,6,
9,5,1,5,
10,5,3,7)
```

##
```{r, echo=FALSE}
ggplot(simp, aes(x=study, y=test.score)) +
    geom_point() +   
    geom_smooth(method=lm,  
                se=FALSE) 
```

## could aggragate across group

```{r}
simp.1<- frame_data(
  ~ID, ~group,  ~test.score, ~study,
  1,1,6,2,
  2,2,5,3,
  3,3,4,4,
  4,4,3,5,
  5,5,2,6)
```

## 

```{r, echo=FALSE}
 ggplot(simp.1, aes(x=study, y=test.score)) +
    geom_point() +    
    geom_smooth(method=lm,   
                se=FALSE) 

```

## what about at the individual level? 

```{r, echo=FALSE}
ggplot(simp, aes(x=study, y=test.score, group = group)) +
    geom_point() +   
    geom_smooth(method=lm,  
                se=FALSE) 
```

## Aggregating is bad
- especially when it is easy to take into account
- Cons of aggregating:
    + reduced power  
    + change the unit of analysis and thus change the meaning  
    + more difficult to make inferences  

## fixed effects regression
$$ \hat{Y}_{i} = b_{0} + b_{1}X_{1} + b_{2}X_{2} + b_{3}X_{3}+...$$
- parameters are considered fixed, only one value  
- can be thought of as purposefully selected or existing values of a variable; can only generalize to particular values used

## random effects
- Can have random parameters that are not fixed, have many values
- 2 ways to think about random  
    + randomly selected from the population (e.g., stimuli are 3 random depression drugs)
    + random as in they are sampled from some population and thus can vary  
-  random effects means that your parameters are predicted and thus have error associated with them
  

##
- Use fixed effects if
    + The groups are regarded as unique entities
    + If group values are determined by researcher through design or manipulation
    
- Use random effects if
    + Groups regarded as a sample from a larger population
    + Understand group differences   
    
##
- what does a random intercept mean?   


  $$ {Y}_{ij} = \beta_{0j}  +\varepsilon_{ij} $$
  
  
  $$ {\beta}_{0} = \gamma_{0} + u_{0j} $$
  
##
- what does a random intercept mean?   


  $$ {Y}_{ij} = \beta_{0j}  +\varepsilon_{ij} $$
  
  
  
  $$ {\beta}_{0j} = \gamma_{00} + u_{0j} $$  
  
  $$ {Y}_{ij} = \gamma_{00} + u_{0j}  + \varepsilon_{ij} $$
  
  
## Level 1 vs Level 2
- Level 1 is the smallest unit of analysis  
    + students, observations, family members

- Level 2 variables are constant for all level 1 variables that are “nested” in it  
    + schools, counties, families, dyads
  
  

