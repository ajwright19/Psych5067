---
title: "Repeated measures & MLM"
author: "Josh Jackson"
date: "4/2/2017"
output: ioslides_presentation
---
## Expanding our toolkit
- We might want to assess people more than once 
- We might want to assess within groups/nested structures 

## Outline
- Repeated Measures ANOVA (RM ANOVA)
- "Mixed" models aka Multilevel models (MLM), hierarchical linear models (HLM), random-effects models, and more...

## Repeated measures ANOVA
- one-way RMANOVA (within subjects ANOVA)
- can also do a mixed designs (both between and within) sometimes refered to as split-plot

## terminology aside
- SS between-groups and SS within-groups 
- between-subjects and within-subjects designs

## why would we want to do this? 

1. our primary interest may be to study the change of an outcome over time, e.g., a learning effect. 
2. multiple outcomes for each subject allows each subject to be his or her own “control”. This allows us to remove subject-to-subject variation (i.e., individidual differences), and likely increasing power 
<br>
<br>
- When would we not want to do this? 

## one way RM ANOVA
- extension of the paired t-test  
- E.g. 
  + A measure before, during and after a intervention  
  + A measure repeated across multiple conditions such as condition A, condition B, and condition C
  + Three or more timepoints (seconds, years, grades)
  
## SS decomposition
- Compared to between subjects, SS residual (within) can be split into 2 different components
- RM ANOVA has SS Treatment, SS subjects, and SS residual
- SS residual still is our measure of leftover error variance
- Smaller error term compared to between subjects 

## NEW Assumptions
The sphericity assumption (also known as the homogeneity of variance of differences assumption) assumes the variance of the  differences between any two levels of a within subjects factor (e.g,. condition, time) is equivalent

- Greenhouse-Geisser Epsilon,
 Huynh-Feldt Epsil,
 Pillai’s Trace,
 Wilk’s Lambda,
 Hotelling’s Trace, and
 Roy’s Largest Root

- adjusts df if violated

## post hoc tests
If the overall ANOVA yields a significant result one can test: 
  + pair-wise comparisons 
  + linear, quadratic trends  
  
##
SS wine and SS subject are calculated with marginals. 

| ID   |wine #1|  #2  | #3  |  #4 | Mean | 
|------|-------|------|-----|-----|------|
| 1    |  2    |  5   |  3  |  3  | 3.25 |  
| 2    |  4    |  6   |  5  |  4  | 4.75 |  
| 3    |  5    |  7   |  4  |  5  | 5.25 |   
| 4    |  3    |  4   |  3  |  4  | 3.5  |  
| 5    |  6    |  7   |  6  |  5  | 6.0  |  
| 6    |  2    |  5   |  4  |  3  | 3.5  |   
| 7    |  4    |  5   |  6  |  4  | 4.75 |
| mean | 3.63  | 5.63 | 4.38| 4.25|      |


## more complex RM designs
- involve interactions
- involve between person (and/or more within person) variables
- involve multiple SS residual terms

## Interactions

$$ Y_{ijk} = \mu + \eta_{j} + \alpha_{k} + \eta \alpha_{jk}+\varepsilon_{ijk} $$



- The interaction variance contributes to both subjects and A factor SSs
- Decreased power (interaction adds noise to error term)
- May increase sphericity

## Mixed designs

- Between and within factor  
<br>
- Wine tasting by groups (sophomores, sommeliers, souses)  
  + Are some wines rated better? (within)  
  + Do groups rate wine differently (between)  
  + Do sommeliers especially dislike merlot? (within- between subjects interaction)  
- Interactions are now interpretable 


## Problems with RM ANOVA


## Nesting and heirarchy
- students within schools
- observations within people 
- members witin family
- people within counties
- observations within people within classrooms within grades within schools within districts within counties within states
<br>
- ignoring this grouping leads to more unexplained variablity
- innacurate comparisons (e.g. simpson's paradox)

## Example
```{r}
library(tidyverse)

simp<- frame_data(
  ~ID, ~group,  ~test.score, ~study,
1,1,5,1,
2,1,7,3,
3,2,4,1,
4,2,6,4,
5,3,3,3,
6,3,5,5,
7,4,2,4,
8,4,4,6,
9,5,1,5,
10,5,3,7)
```

##
```{r, echo=FALSE}
ggplot(simp, aes(x=study, y=test.score)) +
    geom_point() +   
    geom_smooth(method=lm,  
                se=FALSE) 
```

## could aggragate across group

```{r}
simp.1<- frame_data(
  ~ID, ~group,  ~test.score, ~study,
  1,1,6,2,
  2,2,5,3,
  3,3,4,4,
  4,4,3,5,
  5,5,2,6)
```


```{r, echo=FALSE}
 ggplot(simp.1, aes(x=study, y=test.score)) +
    geom_point() +    
    geom_smooth(method=lm,   
                se=FALSE) 

```

```{r, echo=FALSE}
ggplot(simp, aes(x=study, y=test.score, group = group)) +
    geom_point() +   
    geom_smooth(method=lm,  
                se=FALSE) 
```

## Aggregating is bad
- especially when it is easy to take into account
- Cons of aggregating:
  + reduced power
  + change the unit of analysis and thus change the meaning
  + more difficult to make inferences

## Level 1 vs Level 2
- Level 1 is the smallest unit of analysis  
  + students, observations, family members

- Level 2 variables are constant for all level 1 variables that are “nested” in it  
  + schools, counties, families, dyads
  
  

