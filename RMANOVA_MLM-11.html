<!DOCTYPE html>
<html>
<head>
  <title>MLM</title>

  <meta charset="utf-8">
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="generator" content="pandoc" />




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">

  <base target="_blank">

  <script type="text/javascript">
    var SLIDE_CONFIG = {
      // Slide settings
      settings: {
                title: 'MLM',
                        useBuilds: true,
        usePrettify: true,
        enableSlideAreas: true,
        enableTouch: true,
                      },

      // Author information
      presenters: [
            ]
    };
  </script>

  <link href="site_libs/ioslides-13.5.1/fonts/fonts.css" rel="stylesheet" />
  <link href="site_libs/ioslides-13.5.1/theme/css/default.css" rel="stylesheet" />
  <link href="site_libs/ioslides-13.5.1/theme/css/phone.css" rel="stylesheet" />
  <script src="site_libs/ioslides-13.5.1/js/modernizr.custom.45394.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/prettify/prettify.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/prettify/lang-r.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/prettify/lang-yaml.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/hammer.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/slide-controller.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/slide-deck.js"></script>

  <style type="text/css">

    b, strong {
      font-weight: bold;
    }

    em {
      font-style: italic;
    }

    summary {
      display: list-item;
    }

    slides > slide {
      -webkit-transition: all 0.4s ease-in-out;
      -moz-transition: all 0.4s ease-in-out;
      -o-transition: all 0.4s ease-in-out;
      transition: all 0.4s ease-in-out;
    }

    .auto-fadein {
      -webkit-transition: opacity 0.6s ease-in;
      -webkit-transition-delay: 0.4s;
      -moz-transition: opacity 0.6s ease-in 0.4s;
      -o-transition: opacity 0.6s ease-in 0.4s;
      transition: opacity 0.6s ease-in 0.4s;
      opacity: 0;
    }

  </style>


</head>

<body style="opacity: 0">

<slides>

  <slide class="title-slide segue nobackground">
        <!-- The content of this hgroup is replaced programmatically through the slide_config.json. -->
    <hgroup class="auto-fadein">
      <h1 data-config-title><!-- populated from slide_config.json --></h1>
      <h2 data-config-subtitle><!-- populated from slide_config.json --></h2>
      <p data-config-presenter><!-- populated from slide_config.json --></p>
          </hgroup>
  </slide>

<slide class=""><hgroup><h2>Expanding our toolkit</h2></hgroup><article  id="expanding-our-toolkit">

<ul>
<li>We might want to assess people more than once</li>
<li>We might want to assess within groups/nested structures</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Outline</h2></hgroup><article  id="outline">

<ul>
<li>Conceptual Repeated Measures ANOVA (RM ANOVA)</li>
<li>&ldquo;Mixed&rdquo; models aka Multilevel models (MLM), hierarchical linear models (HLM), random-effects models, and more…</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Repeated measures ANOVA</h2></hgroup><article  id="repeated-measures-anova">

<ul>
<li>one-way RMANOVA (within subjects ANOVA)</li>
<li>can also do a mixed designs (both between and within) sometimes refered to as split-plot</li>
</ul>

</article></slide><slide class=""><hgroup><h2>terminology aside</h2></hgroup><article  id="terminology-aside">

<ul>
<li>SS between-groups and SS within-groups</li>
<li>between-subjects and within-subjects designs</li>
</ul>

</article></slide><slide class=""><hgroup><h2>why would we want to do this?</h2></hgroup><article  id="why-would-we-want-to-do-this">

<ol>
<li>our primary interest may be to study the change of an outcome over time, e.g., a learning effect.</li>
<li>multiple outcomes for each subject allows each subject to be his or her own &ldquo;control&rdquo;. This allows us to remove subject-to-subject variation (i.e., individidual differences), likely increasing power <br> <br></li>
</ol>

<ul>
<li>When would we <em>not</em> want to do this?</li>
</ul>

</article></slide><slide class=""><hgroup><h2>one way RM ANOVA</h2></hgroup><article  id="one-way-rm-anova">

<ul>
<li>extension of the paired t-test<br/></li>
<li>E.g.

<ul>
<li>A measure before, during and after a intervention<br/></li>
<li>A measure repeated across multiple conditions such as condition A, condition B, and condition C</li>
<li>Three or more timepoints (seconds, years, grades)</li>
</ul></li>
</ul>

</article></slide><slide class=""><hgroup><h2>SS decomposition</h2></hgroup><article  id="ss-decomposition">

<ul>
<li>SS between: Deviation of subjects’ individual means (across treatments) from the grand mean.</li>
<li>In the RMANOVA, this is largely uninteresting, as we can pretty much assume that &lsquo;subjects differ&rsquo;</li>
</ul>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section">

<table class = 'rmdtable'>
<tr class="header">
<th align="left">ID</th>
<th align="left">wine #1</th>
<th align="left">#2</th>
<th align="left">#3</th>
<th align="left">#4</th>
<th align="left">Mean</th>
</tr>
<tr class="odd">
<td align="left">1</td>
<td align="left">2</td>
<td align="left">5</td>
<td align="left">3</td>
<td align="left">3</td>
<td align="left">3.25</td>
</tr>
<tr class="even">
<td align="left">2</td>
<td align="left">4</td>
<td align="left">6</td>
<td align="left">5</td>
<td align="left">4</td>
<td align="left">4.75</td>
</tr>
<tr class="odd">
<td align="left">3</td>
<td align="left">5</td>
<td align="left">7</td>
<td align="left">4</td>
<td align="left">5</td>
<td align="left">5.25</td>
</tr>
<tr class="even">
<td align="left">4</td>
<td align="left">3</td>
<td align="left">4</td>
<td align="left">3</td>
<td align="left">4</td>
<td align="left">3.5</td>
</tr>
<tr class="odd">
<td align="left">5</td>
<td align="left">6</td>
<td align="left">7</td>
<td align="left">6</td>
<td align="left">5</td>
<td align="left">6.0</td>
</tr>
<tr class="even">
<td align="left">6</td>
<td align="left">2</td>
<td align="left">5</td>
<td align="left">4</td>
<td align="left">3</td>
<td align="left">3.5</td>
</tr>
<tr class="odd">
<td align="left">7</td>
<td align="left">4</td>
<td align="left">5</td>
<td align="left">6</td>
<td align="left">4</td>
<td align="left">4.75</td>
</tr>
<tr class="even">
<td align="left">mean</td>
<td align="left">3.63</td>
<td align="left">5.63</td>
<td align="left">4.38</td>
<td align="left">4.25</td>
<td align="left"></td>
</tr>
</table>

</article></slide><slide class=""><hgroup><h2>SS decomposition</h2></hgroup><article  id="ss-decomposition-1">

<ul>
<li>SS within: how subjects vary about their own mean</li>
<li>Compared to between subjects ANOVA, SS residual (within) is split into 2 different components:</li>
<li>SStreatment

<ul>
<li>As in between subjects ANOVA, comparison of treatment marignal means to grand mean</li>
<li>now a part of the within subjects variation</li>
</ul></li>
<li>SS residual

<ul>
<li>Variability of individuals’ scores about their treatment mean</li>
<li>SS residual still is our measure of leftover error variance</li>
<li>Smaller error term compared to between subjects</li>
</ul></li>
</ul>

</article></slide><slide class=""><hgroup><h2>post hoc tests</h2></hgroup><article  id="post-hoc-tests">

<ul>
<li>If the overall ANOVA yields a significant result one can test:

<ul>
<li>pair-wise comparisons<br/></li>
<li>linear, quadratic trends</li>
</ul></li>
</ul>

</article></slide><slide class=""><hgroup><h2>more complex RM designs</h2></hgroup><article  id="more-complex-rm-designs">

<ul>
<li>involve interactions</li>
<li>involve between person (and/or more within person) variables</li>
<li>involve multiple SS residual terms</li>
<li>logic of testing is the same though</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Mixed designs</h2></hgroup><article  id="mixed-designs">

<ul>
<li>Between and within factor<br/><br></li>
<li>Wine tasting by groups (sophomores, sommeliers, souses)

<ul>
<li>Are some wines rated better? (within)<br/></li>
<li>Do groups rate wine differently (between)<br/></li>
<li>Do sommeliers especially dislike merlot? (within- between subjects interaction)<br/></li>
</ul></li>
<li>Interactions are now interpretable</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Problems with RM ANOVA</h2></hgroup><article  id="problems-with-rm-anova">

<p>The sphericity assumption (also known as the homogeneity of variance of differences assumption) assumes the variance of the differences between any two levels of a within subjects factor (e.g,. condition, time) is equivalent</p>

<ul>
<li>Can adjust df if violated using: Greenhouse-Geisser Epsilon, Huynh-Feldt Epsil, Pillai’s Trace, Wilk’s Lambda, Hotelling’s Trace, or Roy’s Largest Root</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Problems with RM ANOVA</h2></hgroup><article  id="problems-with-rm-anova-1">

<ul>
<li>complete data, no missing cases (unless you do RM MANOVA)</li>
<li>spacing is same for all time points (and subjects)</li>
<li>does not handle continuous predictors</li>
<li>cannot do time varying covariates</li>
<li>no individaul level trends</li>
</ul>

</article></slide><slide class=""><hgroup><h2>which is why you should use</h2></hgroup><article  id="which-is-why-you-should-use">

<ul>
<li><p>MLM, HLM, mixed models, mixed effects, random effects models, etc.</p></li>
<li><p>If you make assumptions and restrictions to this model you can re-create the RM ANOVA</p></li>
</ul>

</article></slide><slide class=""><hgroup><h2>Nesting and heirarchy</h2></hgroup><article  id="nesting-and-heirarchy">

<ul>
<li>students within schools</li>
<li>observations within people</li>
<li>members witin family</li>
<li>people within counties</li>
<li>observations within people within classrooms within grades within schools within districts within counties within states <br></li>
<li>ignoring this grouping leads to more unexplained variablity</li>
<li>innacurate comparisons (e.g. simpson’s paradox)</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Example</h2></hgroup><article  id="example">

<pre class = 'prettyprint lang-r'>library(tidyverse)

simp&lt;- frame_data(
  ~ID, ~group,  ~test.score, ~study,
1,1,5,1,
2,1,7,3,
3,2,4,1,
4,2,6,4,
5,3,3,3,
6,3,5,5,
7,4,2,4,
8,4,4,6,
9,5,1,5,
10,5,3,7)</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-1">

<p><img src="RMANOVA_MLM-11_files/figure-html/unnamed-chunk-2-1.png" width="720" /></p>

</article></slide><slide class=""><hgroup><h2>could aggragate across group</h2></hgroup><article  id="could-aggragate-across-group">

<pre class = 'prettyprint lang-r'>simp.1&lt;- frame_data(
  ~ID, ~group,  ~test.score, ~study,
  1,1,6,2,
  2,2,5,3,
  3,3,4,4,
  4,4,3,5,
  5,5,2,6)</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-2">

<p><img src="RMANOVA_MLM-11_files/figure-html/unnamed-chunk-4-1.png" width="720" /></p>

</article></slide><slide class=""><hgroup><h2>what about at the individual level?</h2></hgroup><article  id="what-about-at-the-individual-level">

<p><img src="RMANOVA_MLM-11_files/figure-html/unnamed-chunk-5-1.png" width="720" /></p>

</article></slide><slide class=""><hgroup><h2>Aggregating is bad</h2></hgroup><article  id="aggregating-is-bad">

<ul>
<li>Especially when it is easy to take into account</li>
<li>Cons of aggregating:

<ul>
<li>reduced power<br/></li>
<li>change the unit of analysis and thus change the meaning<br/></li>
<li>more difficult to make inferences</li>
</ul></li>
</ul>

</article></slide><slide class=""><hgroup><h2>Examining the different levels is good</h2></hgroup><article  id="examining-the-different-levels-is-good">

<ul>
<li><p>Extracurricular activity (EA) and time spent studying</p></li>
<li><p>Between person H1: Do students who participate in EA spend more time studying?</p></li>
<li><p>Within person H2: When a student is participating in EA, do they spend more time studying (e.g., in-season vs. offseason)?</p></li>
<li><p>Notice that H1 and H2 are independent from one another!</p></li>
</ul>

</article></slide><slide class=""><hgroup><h2>fixed effects regression</h2></hgroup><article  id="fixed-effects-regression">

<p>\[ \hat{Y}_{i} = b_{0} + b_{1}X_{1} + b_{2}X_{2} + b_{3}X_{3}+...\] - parameters are considered fixed, only one value<br/>- can be thought of as purposefully selected or existing values of a variable; can only generalize to particular values used</p>

</article></slide><slide class=""><hgroup><h2>random effects</h2></hgroup><article  id="random-effects">

<ul>
<li>Can have random parameters that are not fixed, have many values</li>
<li>2 ways to think about random

<ul>
<li>randomly selected from the population (e.g., stimuli are 3 random depression drugs)</li>
<li>random as in they are sampled from some population and thus can vary<br/></li>
</ul></li>
<li>random effects means that your parameters are predicted and thus have error associated with them</li>
</ul>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-3">

<ul>
<li><p>what does a random intercept mean?</p></li>
<li>Simple model only predicting by an intercept</li>
<li><p>Lets say we have 10 reaction time trials (i) per person (j) \[ {Y}_{ij} = \beta_{0j}  +\varepsilon_{ij} \]</p></li>
<li>We can model that everyone does not have the same average by looking at deviations around that average \(\gamma_{00}\) for each j person \[ {\beta}_{0j} = \gamma_{00} + U_{0j} \]</li>
<li>There are now two sources of error within and between</li>
<li><p>Contrast with if we averaged over people $ {Y}<em>{j} = </em>{0} +_{j}$</p></li>
</ul>

</article></slide><slide class=""><hgroup><h2>putting it together</h2></hgroup><article  id="putting-it-together">

<p>Level 1: \[ {Y}_{ij} = \beta_{0j}  +\varepsilon_{ij} \]</p>

<p>Level 2: \[ {\beta}_{0j} = \gamma_{00} + U_{0j}\]</p>

<p>Combined: \[ {Y}_{ij} = \gamma_{00} + U_{0j}  + \varepsilon_{ij} \]</p>

</article></slide><slide class=""><hgroup><h2>Level 1 vs Level 2</h2></hgroup><article  id="level-1-vs-level-2">

<ul>
<li>Level 1 is the smallest unit of analysis

<ul>
<li>students, observations, trials, family members</li>
</ul></li>
<li>Level 2 variables are constant for all level 1 variables that are &ldquo;nested&rdquo; in it

<ul>
<li>people, schools, counties, families, dyads</li>
</ul></li>
<li>Can have more than 2 levels</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Random intercepts, fixed slopes</h2></hgroup><article  id="random-intercepts-fixed-slopes">

<p>Level 1: \[ {Y}_{ij} = \beta_{0j}  + \beta_{1j}X_{1} + \varepsilon_{ij} \]</p>

<p>Level 2:<br/>\[ {\beta}_{0j} = \gamma_{00} + U_{0j}\]<br/>\[ {\beta}_{1j} = \gamma_{10} \]</p>

<p>Putting it together: \[ {Y}_{ij} = \gamma_{00} + \gamma_{10} (X_{1})+ U_{0j}  + \varepsilon_{ij} \]</p>

</article></slide><slide class=""><hgroup><h2>What does this look like graphically?</h2></hgroup><article  id="what-does-this-look-like-graphically">

<ul>
<li>think of as an individual regressoin for each person</li>
<li>because intercept are random, people can vary</li>
<li>because slopes are fixed, people have the same slope</li>
<li>two types of residuals:

<ul>
<li>represents how much variability there is in the intercepts from person to person</li>
<li>based on individual scores from their predicted score, much like around the regression line</li>
</ul></li>
</ul>

</article></slide><slide class=""><hgroup><h2>Random intercepts, random slopes</h2></hgroup><article  id="random-intercepts-random-slopes">

<p>Level 1: \[ {Y}_{ij} = \beta_{0j}  + \beta_{1j}(X_{1}) + \varepsilon_{ij} \]</p>

<p>Level 2:<br/>\[ {\beta}_{0j} = \gamma_{00} + U_{0j}\]<br/>\[ {\beta}_{1j} = \gamma_{10} + U_{1j} \]</p>

<p>Putting it together: \[ {Y}_{ij} = \gamma_{00} + \gamma_{10}(X_{1})+ U_{0j} + U_{1j} (X_{1})+ \varepsilon_{ij} \]</p>

</article></slide><slide class=""><hgroup><h2>adding covariates and predictors</h2></hgroup><article  id="adding-covariates-and-predictors">

<ul>
<li>can add covariates and predictors at level 1 and level 2</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Estimation</h2></hgroup><article  id="estimation">

<ul>
<li>Maximum Likelihood</li>
<li>Bayesian Estimation</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Data structure</h2></hgroup><article  id="data-structure">

<ul>
<li>long vs wide</li>
<li>use tidyr to convert</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Unconditional model</h2></hgroup><article  id="unconditional-model">

<p>Level 1: \[ {Y}_{ij} = \beta_{0j}  +\varepsilon_{ij} \]</p>

<p>Level 2: \[ {\beta}_{0j} = \gamma_{00} + U_{0j}\]</p>

<p>Combined: \[ {Y}_{ij} = \gamma_{00} + U_{0j}  + \varepsilon_{ij} \]</p>

<p>ICC:</p>

<p>\[\frac{U_{0j}}{U_{0j}+ \varepsilon_{ij}}\]</p>

<ul>
<li>% variation between vs within group (person) variance</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Example</h2></hgroup><article  id="example-1">

<pre class = 'prettyprint lang-r'>alcohol1</pre>

<pre >## # A tibble: 246 x 9
##       id   age   coa  male age_14 alcuse  peer  cpeer  ccoa
##    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;
##  1     1    14     1     0      0   1.73 1.26   0.247 0.549
##  2     1    15     1     0      1   2    1.26   0.247 0.549
##  3     1    16     1     0      2   2    1.26   0.247 0.549
##  4     2    14     1     1      0   0    0.894 -0.124 0.549
##  5     2    15     1     1      1   0    0.894 -0.124 0.549
##  6     2    16     1     1      2   1    0.894 -0.124 0.549
##  7     3    14     1     1      0   1    0.894 -0.124 0.549
##  8     3    15     1     1      1   2    0.894 -0.124 0.549
##  9     3    16     1     1      2   3.32 0.894 -0.124 0.549
## 10     4    14     1     1      0   0    1.79   0.771 0.549
## # … with 236 more rows</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-4">

<pre class = 'prettyprint lang-r'>library(lme4)
model.1 &lt;- lmer(alcuse~ 1 + (1 | id), data = alcohol1)
summary(model.1)</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-5">

<pre >## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: alcuse ~ 1 + (1 | id)
##    Data: alcohol1
## 
## REML criterion at convergence: 673
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -1.8892 -0.3079 -0.3029  0.6111  2.8562 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  id       (Intercept) 0.5731   0.7571  
##  Residual             0.5617   0.7495  
## Number of obs: 246, groups:  id, 82
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)   0.9220     0.0963   9.574</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-6">

<pre class = 'prettyprint lang-r'>library(reghelper)
ICC(model.1)</pre>

<pre >## [1] 0.5050172</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-7">

<pre class = 'prettyprint lang-r'>library(sjPlot)
# sjp.lmer(model.1, facet.grid = FALSE, 
          sort = &quot;sort.all&quot;)</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-8">

<pre class = 'prettyprint lang-r'>model.2 &lt;- lmer(alcuse ~ time + (1 | id), data = alcohol1)
summary(model.2)</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-9">

<pre >## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: alcuse ~ time + (1 | id)
##    Data: alcohol1
## 
## REML criterion at convergence: 654.1
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -2.19816 -0.66940  0.03001  0.44728  2.66167 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  id       (Intercept) 0.5966   0.7724  
##  Residual             0.4915   0.7011  
## Number of obs: 246, groups:  id, 82
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)  0.65130    0.11077   5.880
## time         0.27065    0.05474   4.944
## 
## Correlation of Fixed Effects:
##      (Intr)
## time -0.494</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-10">

<pre class = 'prettyprint lang-r'># sjp.lmer(model.2, type=&quot;fe&quot;)</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-11">

<pre class = 'prettyprint lang-r'>model.3 &lt;- lmer(alcuse ~ time + (1 + time| id), data = alcohol1)
summary(model.3)

## Fixed effects are outside of the parenthesis 
## and the random effects are inside</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-12">

<pre >## Warning in checkConv(attr(opt, &quot;derivs&quot;), opt$par, ctrl =
## control$checkConv, : Model failed to converge with max|grad| = 0.00986507
## (tol = 0.002, component 1)</pre>

<pre >## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: alcuse ~ time + (1 + time | id)
##    Data: alcohol1
## 
## REML criterion at convergence: 643.2
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -2.48441 -0.37859 -0.07889  0.38922  2.49339 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr 
##  id       (Intercept) 0.6361   0.7976        
##           time        0.1553   0.3941   -0.23
##  Residual             0.3369   0.5805        
## Number of obs: 246, groups:  id, 82
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)  0.65130    0.10575   6.159
## time         0.27065    0.06284   4.307
## 
## Correlation of Fixed Effects:
##      (Intr)
## time -0.440
## convergence code: 0
## Model failed to converge with max|grad| = 0.00986507 (tol = 0.002, component 1)</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-13">

<pre class = 'prettyprint lang-r'>library(lmerTest)
summary(model.3)
#gives you p-values, if you really want it</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-14">

<pre class = 'prettyprint lang-r'># sjp.lmer(model.3)</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-15">

<pre class = 'prettyprint lang-r'>ggplot(alcohol1,
   aes(x = time, y = alcuse, group = id)) + stat_smooth(method = &quot;lm&quot;, se = FALSE)</pre>

<p><img src="RMANOVA_MLM-11_files/figure-html/unnamed-chunk-20-1.png" width="720" /></p>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-16">

<pre class = 'prettyprint lang-r'>model.4 &lt;- lmer(alcuse~ time + coa + coa*time + (time | id), data = alcohol1)
summary(model.4)</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-17">

<pre >## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: alcuse ~ time + coa + coa * time + (time | id)
##    Data: alcohol1
## 
## REML criterion at convergence: 631.9
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -2.5522 -0.3827 -0.1063  0.3585  2.3707 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr 
##  id       (Intercept) 0.5069   0.7119        
##           time        0.1586   0.3982   -0.23
##  Residual             0.3373   0.5808        
## Number of obs: 246, groups:  id, 82
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)  0.31595    0.13232   2.388
## time         0.29296    0.08527   3.436
## coa          0.74321    0.19699   3.773
## time:coa    -0.04943    0.12695  -0.389
## 
## Correlation of Fixed Effects:
##          (Intr) time   coa   
## time     -0.460              
## coa      -0.672  0.309       
## time:coa  0.309 -0.672 -0.460</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-18">

<pre class = 'prettyprint lang-r'>tidy(model.4)</pre>

<pre >## Warning in bind_rows_(x, .id): binding factor and character vector,
## coercing into character vector</pre>

<pre >## Warning in bind_rows_(x, .id): binding character and factor vector,
## coercing into character vector</pre>

<pre >## # A tibble: 8 x 5
##   term                    estimate std.error statistic group   
##   &lt;chr&gt;                      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;   
## 1 (Intercept)               0.316     0.132      2.39  fixed   
## 2 time                      0.293     0.0853     3.44  fixed   
## 3 coa                       0.743     0.197      3.77  fixed   
## 4 time:coa                 -0.0494    0.127     -0.389 fixed   
## 5 sd_(Intercept).id         0.712    NA         NA     id      
## 6 sd_time.id                0.398    NA         NA     id      
## 7 cor_(Intercept).time.id  -0.229    NA         NA     id      
## 8 sd_Observation.Residual   0.581    NA         NA     Residual</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-19">

<p>what does this look like for group effects?</p>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-20">

<pre class = 'prettyprint lang-r'>example</pre>

<pre >##     Subject  A Reaction
## 1       308 -1 249.5600
## 2       308 -1 258.7047
## 3       308 -1 250.8006
## 4       308 -1 321.4398
## 5       308 -1 356.8519
## 6       308  1 414.6901
## 7       308  1 382.2038
## 8       308  1 290.1486
## 9       308  1 430.5853
## 10      308  1 466.3535
## 11      309 -1 222.7339
## 12      309 -1 205.2658
## 13      309 -1 202.9778
## 14      309 -1 204.7070
## 15      309 -1 207.7161
## 16      309  1 215.9618
## 17      309  1 213.6303
## 18      309  1 217.7272
## 19      309  1 224.2957
## 20      309  1 237.3142
## 21      310 -1 199.0539
## 22      310 -1 194.3322
## 23      310 -1 234.3200
## 24      310 -1 232.8416
## 25      310 -1 229.3074
## 26      310  1 220.4579
## 27      310  1 235.4208
## 28      310  1 255.7511
## 29      310  1 261.0125
## 30      310  1 247.5153
## 31      330 -1 321.5426
## 32      330 -1 300.4002
## 33      330 -1 283.8565
## 34      330 -1 285.1330
## 35      330 -1 285.7973
## 36      330  1 297.5855
## 37      330  1 280.2396
## 38      330  1 318.2613
## 39      330  1 305.3495
## 40      330  1 354.0487
## 41      331 -1 287.6079
## 42      331 -1 285.0000
## 43      331 -1 301.8206
## 44      331 -1 320.1153
## 45      331 -1 316.2773
## 46      331  1 293.3187
## 47      331  1 290.0750
## 48      331  1 334.8177
## 49      331  1 293.7469
## 50      331  1 371.5811
## 51      332 -1 234.8606
## 52      332 -1 242.8118
## 53      332 -1 272.9613
## 54      332 -1 309.7688
## 55      332 -1 317.4629
## 56      332  1 309.9976
## 57      332  1 454.1619
## 58      332  1 346.8311
## 59      332  1 330.3003
## 60      332  1 253.8644
## 61      333 -1 283.8424
## 62      333 -1 289.5550
## 63      333 -1 276.7693
## 64      333 -1 299.8097
## 65      333 -1 297.1710
## 66      333  1 338.1665
## 67      333  1 332.0265
## 68      333  1 348.8399
## 69      333  1 333.3600
## 70      333  1 362.0428
## 71      334 -1 265.4731
## 72      334 -1 276.2012
## 73      334 -1 243.3647
## 74      334 -1 254.6723
## 75      334 -1 279.0244
## 76      334  1 284.1912
## 77      334  1 305.5248
## 78      334  1 331.5229
## 79      334  1 335.7469
## 80      334  1 377.2990
## 81      335 -1 241.6083
## 82      335 -1 273.9472
## 83      335 -1 254.4907
## 84      335 -1 270.8021
## 85      335 -1 251.4519
## 86      335  1 254.6362
## 87      335  1 245.4523
## 88      335  1 235.3110
## 89      335  1 235.7541
## 90      335  1 237.2466
## 91      337 -1 312.3666
## 92      337 -1 313.8058
## 93      337 -1 291.6112
## 94      337 -1 346.1222
## 95      337 -1 365.7324
## 96      337  1 391.8385
## 97      337  1 404.2601
## 98      337  1 416.6923
## 99      337  1 455.8643
## 100     337  1 458.9167
## 101     349 -1 236.1032
## 102     349 -1 230.3167
## 103     349 -1 238.9256
## 104     349 -1 254.9220
## 105     349 -1 250.7103
## 106     349  1 269.7744
## 107     349  1 281.5648
## 108     349  1 308.1020
## 109     349  1 336.2806
## 110     349  1 351.6451
## 111     350 -1 256.2968
## 112     350 -1 243.4543
## 113     350 -1 256.2046
## 114     350 -1 255.5271
## 115     350 -1 268.9165
## 116     350  1 329.7247
## 117     350  1 379.4445
## 118     350  1 362.9184
## 119     350  1 394.4872
## 120     350  1 389.0527
## 121     351 -1 250.5265
## 122     351 -1 300.0576
## 123     351 -1 269.8939
## 124     351 -1 280.5891
## 125     351 -1 271.8274
## 126     351  1 304.6336
## 127     351  1 287.7466
## 128     351  1 266.5955
## 129     351  1 321.5418
## 130     351  1 347.5655
## 131     352 -1 221.6771
## 132     352 -1 298.1939
## 133     352 -1 326.8785
## 134     352 -1 346.8555
## 135     352 -1 348.7402
## 136     352  1 352.8287
## 137     352  1 354.4266
## 138     352  1 360.4326
## 139     352  1 375.6406
## 140     352  1 388.5417
## 141     369 -1 271.9235
## 142     369 -1 268.4369
## 143     369 -1 257.2424
## 144     369 -1 277.6566
## 145     369 -1 314.8222
## 146     369  1 317.2135
## 147     369  1 298.1353
## 148     369  1 348.1229
## 149     369  1 340.2800
## 150     369  1 366.5131
## 151     370 -1 225.2640
## 152     370 -1 234.5235
## 153     370 -1 238.9008
## 154     370 -1 240.4730
## 155     370 -1 267.5373
## 156     370  1 344.1937
## 157     370  1 281.1481
## 158     370  1 347.5855
## 159     370  1 365.1630
## 160     370  1 372.2288
## 161     371 -1 269.8804
## 162     371 -1 272.4428
## 163     371 -1 277.8989
## 164     371 -1 281.7895
## 165     371 -1 279.1705
## 166     371  1 284.5120
## 167     371  1 259.2658
## 168     371  1 304.6306
## 169     371  1 350.7807
## 170     371  1 369.4692
## 171     372 -1 269.4117
## 172     372 -1 273.4740
## 173     372 -1 297.5968
## 174     372 -1 310.6316
## 175     372 -1 287.1726
## 176     372  1 329.6076
## 177     372  1 334.4818
## 178     372  1 343.2199
## 179     372  1 369.1417
## 180     372  1 364.1236</pre>

<p><img src="RMANOVA_MLM-11_files/figure-html/unnamed-chunk-26-1.png" width="720" /></p>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-21">

<pre class = 'prettyprint lang-r'>ex.1 &lt;- lmer(Reaction ~ 1 + (1|Subject), data = example)
summary(ex.1)</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-22">

<pre >## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: Reaction ~ 1 + (1 | Subject)
##    Data: example
## 
## REML criterion at convergence: 1904.3
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -2.4983 -0.5501 -0.1476  0.5123  3.3446 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  Subject  (Intercept) 1278     35.75   
##  Residual             1959     44.26   
## Number of obs: 180, groups:  Subject, 18
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)   298.51       9.05   32.98</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-23">

<pre class = 'prettyprint lang-r'>library(sjPlot)
#sjp.lmer(ex.1, facet.grid = FALSE,
          sort = &quot;sort.all&quot;)</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-24">

<pre class = 'prettyprint lang-r'>reghelper::ICC(ex.1)</pre>

<pre >## [1] 0.3948898</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-25">

<pre class = 'prettyprint lang-r'>ex.2 &lt;- lmer(Reaction ~ A + (1|Subject), data = example)
summary(ex.2)</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-26">

<pre >## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: Reaction ~ A + (1 | Subject)
##    Data: example
## 
## REML criterion at convergence: 1813.8
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -2.5154 -0.6952  0.0217  0.6144  3.5380 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  Subject  (Intercept) 1358     36.85   
##  Residual             1163     34.11   
## Number of obs: 180, groups:  Subject, 18
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)  271.630      9.400   28.90
## A1            53.755      5.085   10.57
## 
## Correlation of Fixed Effects:
##    (Intr)
## A1 -0.270</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-27">

<p>how can you think of this graphically?</p>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-28">

<pre class = 'prettyprint lang-r'>ex.3 &lt;- lmer(Reaction ~ A + (A|Subject), data = example)
summary(ex.3)</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-29">

<pre >## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: Reaction ~ A + (A | Subject)
##    Data: example
## 
## REML criterion at convergence: 1787.3
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.3007 -0.5091 -0.0314  0.4551  3.8663 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr
##  Subject  (Intercept) 749.1    27.37        
##           A1          975.2    31.23    0.46
##  Residual             905.9    30.10        
## Number of obs: 180, groups:  Subject, 18
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)  271.630      7.189  37.785
## A1            53.755      8.620   6.236
## 
## Correlation of Fixed Effects:
##    (Intr)
## A1 0.188</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-30">

<pre class = 'prettyprint lang-r'>ranef(ex.3)</pre>

<pre >## $Subject
##     (Intercept)         A1
## 308  21.7019920  42.407315
## 309 -55.2428019 -44.640574
## 310 -45.8928542 -33.269923
## 330  11.6391798 -19.841564
## 331  16.6575039 -18.863738
## 332   4.6913460   7.716506
## 333  13.5914343   4.514921
## 334  -4.4328004   4.341370
## 335 -22.2294260 -51.988948
## 337  49.5022719  45.908883
## 349 -20.2344170   1.492485
## 350  -1.3745363  38.016890
## 351  -1.6482370 -14.837734
## 352  28.9498380  12.621214
## 369   5.2872561   3.261798
## 370 -15.1363095  24.261603
## 371   0.7331579  -9.958333
## 372  13.4374024   8.857830
## 
## with conditional variances for &quot;Subject&quot;</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-31">

<pre class = 'prettyprint lang-r'>#sjp.lmer(ex.3)</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-32">

<p>how can you think of this graphically?</p></article></slide>


  <slide class="backdrop"></slide>

</slides>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!-- map slide visiblity events into shiny -->
<script>
  (function() {
    if (window.jQuery) {
       window.jQuery(document).on('slideleave', function(e) {
         window.jQuery(e.target).trigger('hidden');
      });
       window.jQuery(document).on('slideenter', function(e) {
         window.jQuery(e.target).trigger('shown');
      });
    }
  })();
</script>

</body>
</html>
