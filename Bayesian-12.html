<!DOCTYPE html>
<html>
<head>
  <title>Bayesian</title>

  <meta charset="utf-8">
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="generator" content="pandoc" />




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">

  <base target="_blank">

  <script type="text/javascript">
    var SLIDE_CONFIG = {
      // Slide settings
      settings: {
                title: 'Bayesian',
                        useBuilds: true,
        usePrettify: true,
        enableSlideAreas: true,
        enableTouch: true,
                      },

      // Author information
      presenters: [
            ]
    };
  </script>

  <link href="site_libs/ioslides-13.5.1/fonts/fonts.css" rel="stylesheet" />
  <link href="site_libs/ioslides-13.5.1/theme/css/default.css" rel="stylesheet" />
  <link href="site_libs/ioslides-13.5.1/theme/css/phone.css" rel="stylesheet" />
  <script src="site_libs/ioslides-13.5.1/js/modernizr.custom.45394.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/prettify/prettify.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/prettify/lang-r.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/prettify/lang-yaml.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/hammer.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/slide-controller.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/slide-deck.js"></script>

  <style type="text/css">

    b, strong {
      font-weight: bold;
    }

    em {
      font-style: italic;
    }

    slides > slide {
      -webkit-transition: all 0.4s ease-in-out;
      -moz-transition: all 0.4s ease-in-out;
      -o-transition: all 0.4s ease-in-out;
      transition: all 0.4s ease-in-out;
    }

    .auto-fadein {
      -webkit-transition: opacity 0.6s ease-in;
      -webkit-transition-delay: 0.4s;
      -moz-transition: opacity 0.6s ease-in 0.4s;
      -o-transition: opacity 0.6s ease-in 0.4s;
      transition: opacity 0.6s ease-in 0.4s;
      opacity: 0;
    }

  </style>


</head>

<body style="opacity: 0">

<slides>

  <slide class="title-slide segue nobackground">
        <!-- The content of this hgroup is replaced programmatically through the slide_config.json. -->
    <hgroup class="auto-fadein">
      <h1 data-config-title><!-- populated from slide_config.json --></h1>
      <h2 data-config-subtitle><!-- populated from slide_config.json --></h2>
      <p data-config-presenter><!-- populated from slide_config.json --></p>
          </hgroup>
  </slide>

<slide class=""><hgroup><h2>ESP Example</h2></hgroup><article  id="esp-example">

</article></slide><slide class=""><hgroup><h2>ESP Example</h2></hgroup><article  id="esp-example-1">

<ul>
<li>Doesn’t this just seem wrong?</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Prior beliefs are important</h2></hgroup><article  id="prior-beliefs-are-important">

<ul>
<li>cannot be integrated easily within frequentistic statistics</li>
</ul>

</article></slide><slide class=""><hgroup><h2>The effect of observations</h2></hgroup><article  id="the-effect-of-observations">

<ul>
<li>For a rational person, the role of data in statistics is evidentiary<br/><br></li>
<li>Beliefs after observation = Total evidence observed + Beliefs before observation<br/></li>
<li>That is, we combine observational evidence with beliefs to obtain new beliefs: rational learning</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Some definitions</h2></hgroup><article  id="some-definitions">

<ul>
<li>Suppose we have beliefs about a parameter θ (a population mean, a variance, a probability…)<br/></li>
<li>We represent uncertainty with probability distributions<br/></li>
<li>The uncertainty we have about θ is denoted p(θ)<br/></li>
<li>Can express ideas like: P(35&lt;θ&lt;100), E(θ), etc…<br/></li>
<li>Condition on data: Uncertainty in θ after seeing data x is p(θ∣x)</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Using probability theory to change beliefs</h2></hgroup><article  id="using-probability-theory-to-change-beliefs">

<ul>
<li>The central inferential principle in Bayesian statistics is Bayes’ theorem<br/>\[ p(A∣B)=\frac{p(B∣A) p(A)}{p(B)} \]</li>
<li>what is the definition of a p-value?</li>
</ul>

</article></slide><slide class=""><hgroup><h2>How should we assess evidence?</h2></hgroup><article  id="how-should-we-assess-evidence">

<ul>
<li>If uncertainty is represented by probability, then can use Bayes’ theorem:<br/>\[ p(θ∣data) \propto \frac{p(y\mid\theta)}{p(y)} \times p(\theta)\]</li>
<li>Beliefs after (posterior) is proportional to likelihood * prior <br></li>
<li>prior: how sure we were that θ was true, before we observed the data D<br/></li>
<li>likelihood: the probability that you would have observed the data, if that hypothesis were true. (kind of like a sampling distribution)<br/></li>
<li>p(y) is average likelihood, a scaling paramter. Usually intergral.</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Binomial example</h2></hgroup><article  id="binomial-example">

<ul>
<li>get 15 heads in 20 flips. Is this coin biased? \[ p(k|θ) = \binom{n}{k}θ^{k}(1-θ)^{n-k} \]</li>
<li>should our belief about θ change?</li>
<li>what is our prior? \[ θ \sim U(0,1) \]</li>
</ul>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section">

<p><img src="Bayesian-12_files/figure-html/unnamed-chunk-2-1.png" width="720" /></p>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-1">

<p><img src="Bayesian-12_files/figure-html/unnamed-chunk-3-1.png" width="720" /></p>

</article></slide><slide class=""><hgroup><h2>what does this look like in practice?</h2></hgroup><article  id="what-does-this-look-like-in-practice">

<ul>
<li>a difficulty in all of these is to compute the posterior distribution<br/></li>
<li>what you are doing is multiplying a probability distribution by a probability distribution (sometimes many of them)…and you get a distribution in return<br/><br></li>
</ul>

<ol>
<li>computationally difficult<br/></li>
<li>hard to summarize</li>
</ol>

</article></slide><slide class=""><hgroup><h2>what does this look like in practice?</h2></hgroup><article  id="what-does-this-look-like-in-practice-1">

<ul>
<li>Step 1, come up with a descriptive model of the data \[ \hat{y}=\beta_{0}+\beta_{1}X_{1}\]</li>
<li>i.e. what we have been doing all semester</li>
<li>Step 2, describe the variation, sigma, \[ y \sim norm(\hat{y},\sigma) \]</li>
</ul>

</article></slide><slide class=""><hgroup><h2>what does this look like in practice?</h2></hgroup><article  id="what-does-this-look-like-in-practice-2">

<ul>
<li>Step 3, describe a prior distribution on the parameters<br/></li>
<li>Could be non-informative, weak, or moderately informative depending on prior knowledge</li>
</ul>

</article></slide><slide class=""><hgroup><h2>what does this look like in practice?</h2></hgroup><article  id="what-does-this-look-like-in-practice-3">

<ul>
<li>Step 4, interpret posterior distribution<br/></li>
<li>Posterior indicates credible values of the parameters \(\beta_{0}, \beta_{1}, \sigma\) consistent with the data<br/></li>
<li>distribution of parameter values, not data<br/></li>
<li>can look at range of regression lines &lsquo;consistent with the data&rsquo; as opposed to a single best estimate</li>
</ul>

</article></slide><slide class=""><hgroup><h2>what does this look like in practice?</h2></hgroup><article  id="what-does-this-look-like-in-practice-4">

<ul>
<li>Step 5, do a posterior prediction check<br/></li>
<li>Many ways to do this, most typical is to plot predicted data against actual data<br/></li>
<li>Do so by taking potential \(\beta_{0}, \beta_{1}, \sigma\) values (frequency depending on posterior distribution) and randomly generate X values<br/></li>
<li>get (average) predicted values and credible ranges around those values. See if actual data make sense given these predicted values</li>
</ul>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-2">

<pre class = 'prettyprint lang-r'>library(brms)
options (mc.cores=parallel::detectCores ()) # Run on multiple cores

b1 &lt;- brm(alcuse ~ peer, data=alcohol1, chains=3, iter=3000)</pre>

<pre >## Warning in is.na(x): is.na() applied to non-(list or vector) of type &#39;NULL&#39;

## Warning in is.na(x): is.na() applied to non-(list or vector) of type &#39;NULL&#39;

## Warning in is.na(x): is.na() applied to non-(list or vector) of type &#39;NULL&#39;

## Warning in is.na(x): is.na() applied to non-(list or vector) of type &#39;NULL&#39;

## Warning in is.na(x): is.na() applied to non-(list or vector) of type &#39;NULL&#39;</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-3">

<pre >##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: alcuse ~ peer 
##    Data: alcohol1 (Number of observations: 246) 
## Samples: 3 chains, each with iter = 3000; warmup = 1500; thin = 1;
##          total post-warmup samples = 4500
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept     0.30      0.11     0.09     0.51       4124 1.00
## peer          0.61      0.09     0.44     0.78       4243 1.00
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sigma     0.97      0.05     0.89     1.07       3782 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-4">

<pre class = 'prettyprint lang-r'>lm.1 &lt;- lm(alcuse ~ peer, data = alcohol1)
summary(lm.1)</pre>

<pre >## 
## Call:
## lm(formula = alcuse ~ peer, data = alcohol1)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.8405 -0.8472 -0.3039  0.6961  3.1602 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.30389    0.10650   2.854  0.00469 ** 
## peer         0.60739    0.08524   7.126 1.16e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9692 on 244 degrees of freedom
## Multiple R-squared:  0.1723, Adjusted R-squared:  0.1689 
## F-statistic: 50.78 on 1 and 244 DF,  p-value: 1.162e-11</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-5">

<pre class = 'prettyprint lang-r'>plot(b1)</pre>

<p><img src="Bayesian-12_files/figure-html/unnamed-chunk-8-1.png" width="720" /></p>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-6">

<pre class = 'prettyprint lang-r'>library(shinystan)
launch_shiny(b1) </pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-7">

<pre class = 'prettyprint lang-r'>pp_check(b1, re_formula = NA, type = &quot;dens_overlay&quot;)</pre>

<pre >## Warning in is.na(x): is.na() applied to non-(list or vector) of type &#39;NULL&#39;</pre>

<pre >## Using 10 posterior samples for ppc type &#39;dens_overlay&#39; by default.</pre>

<pre >## Warning in is.na(x): is.na() applied to non-(list or vector) of type &#39;NULL&#39;

## Warning in is.na(x): is.na() applied to non-(list or vector) of type &#39;NULL&#39;

## Warning in is.na(x): is.na() applied to non-(list or vector) of type &#39;NULL&#39;</pre>

<p><img src="Bayesian-12_files/figure-html/unnamed-chunk-10-1.png" width="720" /></p>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article  id="section-8">

<pre class = 'prettyprint lang-r'>pp_check(b1, type = &quot;scatter_avg&quot;, nsamples = 100)</pre>

<pre >## Warning in is.na(x): is.na() applied to non-(list or vector) of type &#39;NULL&#39;

## Warning in is.na(x): is.na() applied to non-(list or vector) of type &#39;NULL&#39;

## Warning in is.na(x): is.na() applied to non-(list or vector) of type &#39;NULL&#39;

## Warning in is.na(x): is.na() applied to non-(list or vector) of type &#39;NULL&#39;</pre>

<p><img src="Bayesian-12_files/figure-html/unnamed-chunk-11-1.png" width="720" /></p>

</article></slide><slide class=""><hgroup><h2>Bayes Factor</h2></hgroup><article  id="bayes-factor"></article></slide>


  <slide class="backdrop"></slide>

</slides>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!-- map slide visiblity events into shiny -->
<script>
  (function() {
    if (window.jQuery) {
       window.jQuery(document).on('slideleave', function(e) {
         window.jQuery(e.target).trigger('hidden');
      });
       window.jQuery(document).on('slideenter', function(e) {
         window.jQuery(e.target).trigger('shown');
      });
    }
  })();
</script>

</body>
</html>
