<!DOCTYPE html>
<html>
<head>
  <title>Repeated measures &amp; MLM</title>

  <meta charset="utf-8">
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="generator" content="pandoc" />




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">

  <base target="_blank">

  <script type="text/javascript">
    var SLIDE_CONFIG = {
      // Slide settings
      settings: {
                title: 'Repeated measures &amp; MLM',
                        useBuilds: true,
        usePrettify: true,
        enableSlideAreas: true,
        enableTouch: true,
                      },

      // Author information
      presenters: [
            ]
    };
  </script>

  <link href="site_libs/ioslides-13.5.1/fonts/fonts.css" rel="stylesheet" />
  <link href="site_libs/ioslides-13.5.1/theme/css/default.css" rel="stylesheet" />
  <link href="site_libs/ioslides-13.5.1/theme/css/phone.css" rel="stylesheet" />
  <script src="site_libs/ioslides-13.5.1/js/modernizr.custom.45394.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/prettify/prettify.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/prettify/lang-r.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/prettify/lang-yaml.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/hammer.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/slide-controller.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/slide-deck.js"></script>

  <style type="text/css">

    b, strong {
      font-weight: bold;
    }

    em {
      font-style: italic;
    }

    slides > slide {
      -webkit-transition: all 0.4s ease-in-out;
      -moz-transition: all 0.4s ease-in-out;
      -o-transition: all 0.4s ease-in-out;
      transition: all 0.4s ease-in-out;
    }

    .auto-fadein {
      -webkit-transition: opacity 0.6s ease-in;
      -webkit-transition-delay: 0.4s;
      -moz-transition: opacity 0.6s ease-in 0.4s;
      -o-transition: opacity 0.6s ease-in 0.4s;
      transition: opacity 0.6s ease-in 0.4s;
      opacity: 0;
    }

  </style>


</head>

<body style="opacity: 0">

<slides>

  <slide class="title-slide segue nobackground">
        <!-- The content of this hgroup is replaced programmatically through the slide_config.json. -->
    <hgroup class="auto-fadein">
      <h1 data-config-title><!-- populated from slide_config.json --></h1>
      <h2 data-config-subtitle><!-- populated from slide_config.json --></h2>
      <p data-config-presenter><!-- populated from slide_config.json --></p>
          </hgroup>
  </slide>

<slide class=''><hgroup><h2>Expanding our toolkit</h2></hgroup><article  id="expanding-our-toolkit">

<ul>
<li>We might want to assess people more than once</li>
<li>We might want to assess within groups/nested structures</li>
</ul>

</article></slide><slide class=''><hgroup><h2>Outline</h2></hgroup><article  id="outline">

<ul>
<li>Repeated Measures ANOVA (RM ANOVA)</li>
<li>&quot;Mixed&quot; models aka Multilevel models (MLM), hierarchical linear models (HLM), random-effects models, and more&#8230;</li>
</ul>

</article></slide><slide class=''><hgroup><h2>Repeated measures ANOVA</h2></hgroup><article  id="repeated-measures-anova">

<ul>
<li>one-way RMANOVA (within subjects ANOVA)</li>
<li>can also do a mixed designs (both between and within) sometimes refered to as split-plot</li>
</ul>

</article></slide><slide class=''><hgroup><h2>terminology aside</h2></hgroup><article  id="terminology-aside">

<ul>
<li>SS between-groups and SS within-groups</li>
<li>between-subjects and within-subjects designs</li>
</ul>

</article></slide><slide class=''><hgroup><h2>why would we want to do this?</h2></hgroup><article  id="why-would-we-want-to-do-this">

<ol>
<li>our primary interest may be to study the change of an outcome over time, e.g., a learning effect.</li>
<li>multiple outcomes for each subject allows each subject to be his or her own “control”. This allows us to remove subject-to-subject variation (i.e., individidual differences), and likely increasing power <br> <br></li>
</ol>

<ul>
<li>When would we <em>not</em> want to do this?</li>
</ul>

</article></slide><slide class=''><hgroup><h2>one way RM ANOVA</h2></hgroup><article  id="one-way-rm-anova">

<ul>
<li>extension of the paired t-test<br/></li>
<li>E.g.

<ul>
<li>A measure before, during and after a intervention<br/></li>
<li>A measure repeated across multiple conditions such as condition A, condition B, and condition C</li>
<li>Three or more timepoints (seconds, years, grades)</li>
</ul></li>
</ul>

</article></slide><slide class=''><hgroup><h2>traditional way (univariate) vs &quot;new&quot; way (multivariate MANOVA)</h2></hgroup><article  id="traditional-way-univariate-vs-new-way-multivariate-manova">

<ul>
<li>different ways to overcome violation of independence</li>
<li>rabbit hole of complexity that is mostly not worth it&#8230;</li>
<li>because there are newer and better methods</li>
<li>nevertheless, let us persist</li>
</ul>

</article></slide><slide class=''><hgroup><h2>SS decomposition</h2></hgroup><article  id="ss-decomposition">

<ul>
<li>SS between: Deviation of subjects&#39; individual means (across treatments) from the grand mean.</li>
<li>In the RMANOVA, this is largely uninteresting, as we can pretty much assume that ‘subjects differ’</li>
</ul>

</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section">

<table class = 'rmdtable'>
<tr class="header">
<th align="left">ID</th>
<th align="left">wine #1</th>
<th align="left">#2</th>
<th align="left">#3</th>
<th align="left">#4</th>
<th align="left">Mean</th>
</tr>
<tr class="odd">
<td align="left">1</td>
<td align="left">2</td>
<td align="left">5</td>
<td align="left">3</td>
<td align="left">3</td>
<td align="left">3.25</td>
</tr>
<tr class="even">
<td align="left">2</td>
<td align="left">4</td>
<td align="left">6</td>
<td align="left">5</td>
<td align="left">4</td>
<td align="left">4.75</td>
</tr>
<tr class="odd">
<td align="left">3</td>
<td align="left">5</td>
<td align="left">7</td>
<td align="left">4</td>
<td align="left">5</td>
<td align="left">5.25</td>
</tr>
<tr class="even">
<td align="left">4</td>
<td align="left">3</td>
<td align="left">4</td>
<td align="left">3</td>
<td align="left">4</td>
<td align="left">3.5</td>
</tr>
<tr class="odd">
<td align="left">5</td>
<td align="left">6</td>
<td align="left">7</td>
<td align="left">6</td>
<td align="left">5</td>
<td align="left">6.0</td>
</tr>
<tr class="even">
<td align="left">6</td>
<td align="left">2</td>
<td align="left">5</td>
<td align="left">4</td>
<td align="left">3</td>
<td align="left">3.5</td>
</tr>
<tr class="odd">
<td align="left">7</td>
<td align="left">4</td>
<td align="left">5</td>
<td align="left">6</td>
<td align="left">4</td>
<td align="left">4.75</td>
</tr>
<tr class="even">
<td align="left">mean</td>
<td align="left">3.63</td>
<td align="left">5.63</td>
<td align="left">4.38</td>
<td align="left">4.25</td>
<td align="left"></td>
</tr>
</table>

</article></slide><slide class=''><hgroup><h2>SS decomposition</h2></hgroup><article  id="ss-decomposition-1">

<ul>
<li>SS within: how subjects vary about their own mean</li>
<li>Compared to between subjects ANOVA, SS residual (within) is split into 2 different components:</li>
<li>SStreatment

<ul>
<li>As in between subjects ANOVA, comparison of treatment marignal means to grand mean</li>
<li>now a part of the within subjects variation</li>
</ul></li>
<li>SS residual

<ul>
<li>Variability of individuals’ scores about their treatment mean</li>
<li>SS residual still is our measure of leftover error variance</li>
</ul></li>
<li>Smaller error term compared to between subjects</li>
</ul>

</article></slide><slide class=''><hgroup><h2>post hoc tests</h2></hgroup><article  id="post-hoc-tests">

<ul>
<li>If the overall ANOVA yields a significant result one can test:

<ul>
<li>pair-wise comparisons<br/></li>
<li>linear, quadratic trends</li>
</ul></li>
</ul>

</article></slide><slide class=''><hgroup><h2>more complex RM designs</h2></hgroup><article  id="more-complex-rm-designs">

<ul>
<li>involve interactions</li>
<li>involve between person (and/or more within person) variables</li>
<li>involve multiple SS residual terms</li>
</ul>

</article></slide><slide class=''><hgroup><h2>Interactions</h2></hgroup><article  id="interactions">

<p>\[ Y_{ijk} = \mu + \eta_{j} + \alpha_{k} + \eta \alpha_{jk}+\varepsilon_{ijk} \]</p>

<ul>
<li>The interaction variance contributes to both subjects and A factor SSs</li>
<li>Decreased power (interaction adds noise to error term)</li>
<li>May increase sphericity</li>
</ul>

</article></slide><slide class=''><hgroup><h2>Mixed designs</h2></hgroup><article  id="mixed-designs">

<ul>
<li>Between and within factor<br/><br></li>
<li>Wine tasting by groups (sophomores, sommeliers, souses)<br/></li>
<li>Are some wines rated better? (within)<br/></li>
<li>Do groups rate wine differently (between)<br/></li>
<li>Do sommeliers especially dislike merlot? (within- between subjects interaction)<br/></li>
<li>Interactions are now interpretable</li>
</ul>

</article></slide><slide class=''><hgroup><h2>Problems with RM ANOVA</h2></hgroup><article  id="problems-with-rm-anova">

<p>The sphericity assumption (also known as the homogeneity of variance of differences assumption) assumes the variance of the differences between any two levels of a within subjects factor (e.g,. condition, time) is equivalent</p>

<ul>
<li><p>Greenhouse-Geisser Epsilon,  Huynh-Feldt Epsil,  Pillai’s Trace,  Wilk’s Lambda,  Hotelling’s Trace, and  Roy’s Largest Root</p></li>
<li>adjusts df if violated</li>
<li><p>but unlikely to find this with observational data</p></li>
</ul>

</article></slide><slide class=''><hgroup><h2>Problems with RM ANOVA</h2></hgroup><article  id="problems-with-rm-anova-1">

<ul>
<li>complete data, no missing cases (unless you do RM MANOVA)</li>
<li>spacing is same for all time points (and subjects)</li>
<li>does not handle continuous data</li>
<li>cannot do time varying covariates</li>
<li>no individaul level trends</li>
</ul>

</article></slide><slide class=''><hgroup><h2>which is why you should use</h2></hgroup><article  id="which-is-why-you-should-use">

<ul>
<li>MLM, HLM, mixed models, mixed effects, random effects models, etc.</li>
</ul>

</article></slide><slide class=''><hgroup><h2>Nesting and heirarchy</h2></hgroup><article  id="nesting-and-heirarchy">

<ul>
<li>students within schools</li>
<li>observations within people</li>
<li>members witin family</li>
<li>people within counties</li>
<li>observations within people within classrooms within grades within schools within districts within counties within states <br></li>
<li>ignoring this grouping leads to more unexplained variablity</li>
<li>innacurate comparisons (e.g. simpson&#39;s paradox)</li>
</ul>

</article></slide><slide class=''><hgroup><h2>Example</h2></hgroup><article  id="example">

<pre class = 'prettyprint lang-r'>library(tidyverse)

simp&lt;- frame_data(
  ~ID, ~group,  ~test.score, ~study,
1,1,5,1,
2,1,7,3,
3,2,4,1,
4,2,6,4,
5,3,3,3,
6,3,5,5,
7,4,2,4,
8,4,4,6,
9,5,1,5,
10,5,3,7)</pre>

</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section-1">

<p><img src="RMANOVA_MLM-9_files/figure-html/unnamed-chunk-2-1.png" width="720" /></p>

</article></slide><slide class=''><hgroup><h2>could aggragate across group</h2></hgroup><article  id="could-aggragate-across-group">

<pre class = 'prettyprint lang-r'>simp.1&lt;- frame_data(
  ~ID, ~group,  ~test.score, ~study,
  1,1,6,2,
  2,2,5,3,
  3,3,4,4,
  4,4,3,5,
  5,5,2,6)</pre>

</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section-2">

<p><img src="RMANOVA_MLM-9_files/figure-html/unnamed-chunk-4-1.png" width="720" /></p>

</article></slide><slide class=''><hgroup><h2>what about at the individual level?</h2></hgroup><article  id="what-about-at-the-individual-level">

<p><img src="RMANOVA_MLM-9_files/figure-html/unnamed-chunk-5-1.png" width="720" /></p>

</article></slide><slide class=''><hgroup><h2>Aggregating is bad</h2></hgroup><article  id="aggregating-is-bad">

<ul>
<li>Especially when it is easy to take into account</li>
<li>Cons of aggregating:

<ul>
<li>reduced power<br/></li>
<li>change the unit of analysis and thus change the meaning<br/></li>
<li>more difficult to make inferences</li>
</ul></li>
</ul>

</article></slide><slide class=''><hgroup><h2>Examining the different levels is good</h2></hgroup><article  id="examining-the-different-levels-is-good">

<ul>
<li><p>Extracurricular activity (EA) and time spent studying</p></li>
<li><p>Between person H1: Do students who participate in EA spend more time studying?</p></li>
<li><p>Within person H2: When a student is participating in EA, do they spend more time studying (e.g., in-season vs. offseason)?</p></li>
<li><p>Notice that H1 and H2 are independent from one another!</p></li>
</ul>

</article></slide><slide class=''><hgroup><h2>fixed effects regression</h2></hgroup><article  id="fixed-effects-regression">

<p>\[ \hat{Y}_{i} = b_{0} + b_{1}X_{1} + b_{2}X_{2} + b_{3}X_{3}+...\] - parameters are considered fixed, only one value<br/>- can be thought of as purposefully selected or existing values of a variable; can only generalize to particular values used</p>

</article></slide><slide class=''><hgroup><h2>fixed effects regression</h2></hgroup><article  id="fixed-effects-regression-1">

<ul>
<li>easy to see in ANOVA models</li>
</ul>

<p>\[ Y_{ij} = \mu + \alpha_{j}+e_{ij}\] - \(\alpha\) is the fixed effect if group j - we don&#39;t randomly select treatments, paradigms are purposely created to test a particular manipulation - or are they? How many types of sad movies can you come up with?</p>

</article></slide><slide class=''><hgroup><h2>random effects</h2></hgroup><article  id="random-effects">

<ul>
<li>Can have random parameters that are not fixed, have many values</li>
<li>2 ways to think about random

<ul>
<li>randomly selected from the population (e.g., stimuli are 3 random depression drugs)</li>
<li>random as in they are sampled from some population and thus can vary<br/></li>
</ul></li>
<li>random effects means that your parameters are predicted and thus have error associated with them</li>
</ul>

</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section-3">

<ul>
<li>Use fixed effects if

<ul>
<li>The groups are regarded as unique entities</li>
<li>If group values are determined by researcher through design or manipulation</li>
</ul></li>
<li>Use random effects if

<ul>
<li>Groups regarded as a sample from a larger population</li>
<li>Understand group differences</li>
<li>Account for more</li>
</ul></li>
</ul>

</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section-4">

<ul>
<li>what does a random intercept mean?</li>
</ul>

<p>\[ {Y}_{ij} = \beta_{0j}  +\varepsilon_{ij} \]</p>

<p>\[ {\beta}_{0j} = \gamma_{00} + U_{0j} \]</p>

</article></slide><slide class=''><hgroup><h2>graphically what does this look like?</h2></hgroup><article  id="graphically-what-does-this-look-like">

<ul>
<li>different intercepts for each j unit, a random effects model.</li>
<li>repeated assessments of happiness taken daily for two weeks</li>
<li>think about this as per subject</li>
</ul>

</article></slide><slide class=''><hgroup><h2>putting it together</h2></hgroup><article  id="putting-it-together">

<p>\[ {Y}_{ij} = \beta_{0j}  +\varepsilon_{ij} \]</p>

<p>\[ {\beta}_{0j} = \gamma_{00} + U_{0j}\]</p>

<p>\[ {Y}_{ij} = \gamma_{00} + U_{0j}  + \varepsilon_{ij} \] - two random terms, two types of variances</p>

</article></slide><slide class=''><hgroup><h2>Level 1 vs Level 2</h2></hgroup><article  id="level-1-vs-level-2">

<ul>
<li>Level 1 is the smallest unit of analysis

<ul>
<li>students, observations, family members</li>
</ul></li>
<li>Level 2 variables are constant for all level 1 variables that are “nested” in it

<ul>
<li>schools, counties, families, dyads</li>
</ul></li>
</ul>

</article></slide><slide class=''><hgroup><h2>Random intercepts, fixed slopes</h2></hgroup><article  id="random-intercepts-fixed-slopes">

<p>Level 1: \[ {Y}_{ij} = \beta_{0j}  + \beta_{1j}X_{1} + \varepsilon_{ij} \]</p>

<p>Level 2:<br/>\[ {\beta}_{0j} = \gamma_{00} + U_{0j}\]<br/>\[ {\beta}_{1j} = \gamma_{10} \]</p>

<p>Putting it together: \[ {Y}_{ij} = \gamma_{00} + \gamma_{10} (X_{1})+ U_{0j}  + \varepsilon_{ij} \]</p>

</article></slide><slide class=''><hgroup><h2>What does this look like graphically?</h2></hgroup><article  id="what-does-this-look-like-graphically">

<ul>
<li>think of as an individual regressoin for each person</li>
<li>because intercept are random, people can vary</li>
<li>because slopes are fixed, people have the same slope</li>
<li>two types of residuals:

<ul>
<li>represents how much variability there is in the intercepts from person to person</li>
<li>based on individual scores from their predicted score, much like around the regression line</li>
</ul></li>
</ul>

</article></slide><slide class=''><hgroup><h2>Random intercepts, random slopes</h2></hgroup><article  id="random-intercepts-random-slopes">

<p>Level 1: \[ {Y}_{ij} = \beta_{0j}  + \beta_{1j}(X_{1}) + \varepsilon_{ij} \]</p>

<p>Level 2:<br/>\[ {\beta}_{0j} = \gamma_{00} + U_{0j}\]<br/>\[ {\beta}_{1j} = \gamma_{10} + U_{1j} \]</p>

<p>Putting it together: \[ {Y}_{ij} = \gamma_{00} + \gamma_{10}(X_{1})+ U_{0j} + U_{1j} (X_{1})+ \varepsilon_{ij} \]</p>

</article></slide><slide class=''><hgroup><h2>adding covariates and predictors</h2></hgroup><article  id="adding-covariates-and-predictors">

<ul>
<li>can add covariates and predictors at level 1 and level 2</li>
</ul>

</article></slide><slide class=''><hgroup><h2>Estimation</h2></hgroup><article  id="estimation">

<ul>
<li>Maximum Likelihood</li>
<li>Bayesian Estimation</li>
</ul>

</article></slide><slide class=''><hgroup><h2>Data structure</h2></hgroup><article  id="data-structure">

<ul>
<li>long vs wide</li>
<li>use tidyr to convert</li>
</ul>

</article></slide><slide class=''><hgroup><h2>Unconditional model</h2></hgroup><article  id="unconditional-model">

<p>Level 1: \[ {Y}_{ij} = \beta_{0j}  +\varepsilon_{ij} \]</p>

<p>Level 2: \[ {\beta}_{0j} = \gamma_{00} + U_{0j}\]</p>

<p>Combined: \[ {Y}_{ij} = \gamma_{00} + U_{0j}  + \varepsilon_{ij} \]</p>

<p>ICC:</p>

<p>\[\frac{U_{0j}}{U_{0j}+ \varepsilon_{ij}}\]</p>

<ul>
<li>% variation between vs within group (person) variance</li>
</ul>

</article></slide><slide class=''><hgroup><h2>Example</h2></hgroup><article  id="example-1">

<pre class = 'prettyprint lang-r'>alcohol1</pre>

<pre >## # A tibble: 246 × 9
##       id   age   coa  male age_14   alcuse      peer      cpeer  ccoa
##    &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;
## 1      1    14     1     0      0 1.732051 1.2649111  0.2469111 0.549
## 2      1    15     1     0      1 2.000000 1.2649111  0.2469111 0.549
## 3      1    16     1     0      2 2.000000 1.2649111  0.2469111 0.549
## 4      2    14     1     1      0 0.000000 0.8944272 -0.1235728 0.549
## 5      2    15     1     1      1 0.000000 0.8944272 -0.1235728 0.549
## 6      2    16     1     1      2 1.000000 0.8944272 -0.1235728 0.549
## 7      3    14     1     1      0 1.000000 0.8944272 -0.1235728 0.549
## 8      3    15     1     1      1 2.000000 0.8944272 -0.1235728 0.549
## 9      3    16     1     1      2 3.316625 0.8944272 -0.1235728 0.549
## 10     4    14     1     1      0 0.000000 1.7888544  0.7708544 0.549
## # ... with 236 more rows</pre>

</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section-5">

<pre class = 'prettyprint lang-r'>library(lme4)
model.1 &lt;- lmer(alcuse~ 1 + (1 | id), data = alcohol1)
summary(model.1)</pre>

</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section-6">

<pre >## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: alcuse ~ 1 + (1 | id)
##    Data: alcohol1
## 
## REML criterion at convergence: 673
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -1.8892 -0.3079 -0.3029  0.6111  2.8562 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  id       (Intercept) 0.5731   0.7571  
##  Residual             0.5617   0.7495  
## Number of obs: 246, groups:  id, 82
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)   0.9220     0.0963   9.574</pre>

</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section-7">

<<<<<<< HEAD
<pre class = 'prettyprint lang-r'>library(reghelper)
ICC(model.1)</pre>

<pre >## [1] 0.5050172</pre>
=======
<pre class = 'prettyprint lang-r'>library(reghelper)</pre>

<pre >## 
## Attaching package: &#39;reghelper&#39;</pre>

<pre >## The following object is masked from &#39;package:psych&#39;:
## 
##     ICC</pre>

<pre >## The following object is masked from &#39;package:base&#39;:
## 
##     beta</pre>

<pre class = 'prettyprint lang-r'>ICC(model.1)</pre>

<pre >## [1] 0.5050172</pre>

</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section-8">

<pre class = 'prettyprint lang-r'>library(sjPlot)
sjp.lmer(model.1, facet.grid = FALSE, 
          sort = &quot;sort.all&quot;)</pre>

<p><img src="RMANOVA_MLM-9_files/figure-html/unnamed-chunk-11-1.png" width="720" /></p>

</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section-9">

<pre class = 'prettyprint lang-r'>alcohol1$time &lt;- alcohol1$age -14 
model.2 &lt;- lmer(alcuse ~ time + (1| id), data = alcohol1)
summary(model.2)</pre>
>>>>>>> 780f7577a252270721a2bdb46a39555798d4bcf9

</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section-10">

<pre class = 'prettyprint lang-r'>library(sjPlot)
sjp.lmer(model.1, facet.grid = FALSE, 
          sort = &quot;sort.all&quot;)</pre>

<p><img src="RMANOVA_MLM-9_files/figure-html/unnamed-chunk-11-1.png" width="720" /></p>

</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section-11">

<pre class = 'prettyprint lang-r'>sjp.lmer(model.2, type=&quot;fe&quot;)</pre>

<pre >## Computing p-values via Kenward-Roger approximation. Use `p.kr = FALSE` if computation takes too long.</pre>

<p><img src="RMANOVA_MLM-9_files/figure-html/unnamed-chunk-14-1.png" width="720" /></p>

</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section-12">

<pre class = 'prettyprint lang-r'>alcohol1$time &lt;- alcohol1$age -14 
model.2 &lt;- lmer(alcuse ~ time + (1| id), data = alcohol1)
summary(model.2)</pre>

</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section-10">

<pre class = 'prettyprint lang-r'>model.3 &lt;- lmer(alcuse ~ time + (1 + time| id), data = alcohol1)
summary(model.3)

## Fixed effects are outside of the parenthesis 
## and the random effects are inside</pre>

<<<<<<< HEAD
</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section-11">
=======
</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section-13">
>>>>>>> 780f7577a252270721a2bdb46a39555798d4bcf9

<pre >## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: alcuse ~ time + (1 + time | id)
##    Data: alcohol1
## 
## REML criterion at convergence: 643.2
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -2.48287 -0.37933 -0.07858  0.38876  2.49284 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr 
##  id       (Intercept) 0.6355   0.7972        
##           time        0.1552   0.3939   -0.23
##  Residual             0.3373   0.5808        
## Number of obs: 246, groups:  id, 82
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)  0.65130    0.10573   6.160
## time         0.27065    0.06284   4.307
## 
## Correlation of Fixed Effects:
##      (Intr)
## time -0.441</pre>

<<<<<<< HEAD
</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section-12">
=======
</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section-14">
>>>>>>> 780f7577a252270721a2bdb46a39555798d4bcf9

<pre class = 'prettyprint lang-r'>library(lmerTest)
summary(model.3)</pre>

<<<<<<< HEAD
</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section-13">

<pre class = 'prettyprint lang-r'>library(sjPlot)
sjp.lmer(model.3, facet.grid = FALSE,
          sort = &quot;sort.all&quot;)</pre>

<p><img src="RMANOVA_MLM-9_files/figure-html/unnamed-chunk-16-1.png" width="720" /><img src="RMANOVA_MLM-9_files/figure-html/unnamed-chunk-16-2.png" width="720" /></p>

</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section-14">
=======
</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section-15">

<pre class = 'prettyprint lang-r'>library(sjPlot)
sjp.lmer(model.3, 
          sort = &quot;sort.all&quot;)</pre>

<pre >## Sorting each group of random intercept (&#39;sort.all&#39;) is not possible when &#39;facet.grid = TRUE&#39;.
## Sorting each group of random intercept (&#39;sort.all&#39;) is not possible when &#39;facet.grid = TRUE&#39;.</pre>

<pre >## Plotting random effects...</pre>

<p><img src="RMANOVA_MLM-9_files/figure-html/unnamed-chunk-18-1.png" width="720" /></p>

</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section-16">
>>>>>>> 780f7577a252270721a2bdb46a39555798d4bcf9

<pre class = 'prettyprint lang-r'>ggplot(alcohol1,
   aes(x = time, y = alcuse, group = id)) + stat_smooth(method = &quot;lm&quot;, se = FALSE)</pre>

<<<<<<< HEAD
<p><img src="RMANOVA_MLM-9_files/figure-html/unnamed-chunk-17-1.png" width="720" /></p>

</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section-15">

</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section-16">
=======
<p><img src="RMANOVA_MLM-9_files/figure-html/unnamed-chunk-19-1.png" width="720" /></p>

</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section-17">

</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section-18">
>>>>>>> 780f7577a252270721a2bdb46a39555798d4bcf9

<pre class = 'prettyprint lang-r'>model.4 &lt;- lmer(alcuse~ time + coa + coa*time + (time | id), data = alcohol1)
summary(model.4)</pre>

<<<<<<< HEAD
</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section-17">
=======
</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section-19">
>>>>>>> 780f7577a252270721a2bdb46a39555798d4bcf9

<pre >## Linear mixed model fit by REML t-tests use Satterthwaite approximations
##   to degrees of freedom [lmerMod]
## Formula: alcuse ~ time + coa + coa * time + (time | id)
##    Data: alcohol1
## 
## REML criterion at convergence: 631.9
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -2.5522 -0.3827 -0.1063  0.3585  2.3708 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr 
##  id       (Intercept) 0.5068   0.7119        
##           time        0.1586   0.3982   -0.23
##  Residual             0.3373   0.5808        
## Number of obs: 246, groups:  id, 82
## 
## Fixed effects:
##             Estimate Std. Error       df t value Pr(&gt;|t|)    
## (Intercept)  0.31595    0.13232 80.00000   2.388 0.019307 *  
## time         0.29296    0.08527 80.00000   3.435 0.000941 ***
## coa          0.74321    0.19698 80.00000   3.773 0.000308 ***
## time:coa    -0.04943    0.12695 80.00000  -0.389 0.698034    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##          (Intr) time   coa   
## time     -0.460              
## coa      -0.672  0.309       
## time:coa  0.309 -0.672 -0.460</pre>

<<<<<<< HEAD
</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section-18">
=======
</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section-20">
>>>>>>> 780f7577a252270721a2bdb46a39555798d4bcf9

<pre class = 'prettyprint lang-r'>tidy(model.4)</pre>

<pre >##                      term    estimate  std.error  statistic    group
## 1             (Intercept)  0.31595172 0.13231891  2.3878047    fixed
## 2                    time  0.29295517 0.08527403  3.4354557    fixed
## 3                     coa  0.74321203 0.19698266  3.7729821    fixed
## 4                time:coa -0.04942994 0.12694713 -0.3893742    fixed
## 5       sd_(Intercept).id  0.71189636         NA         NA       id
## 6              sd_time.id  0.39821932         NA         NA       id
## 7 cor_(Intercept).time.id -0.22943387         NA         NA       id
## 8 sd_Observation.Residual  0.58076865         NA         NA Residual</pre>

<<<<<<< HEAD
</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section-19">
=======
</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section-21">
>>>>>>> 780f7577a252270721a2bdb46a39555798d4bcf9

<pre class = 'prettyprint lang-r'>example &lt;- sleepstudy %&gt;%
  mutate(A = ifelse(Days &lt; 5, -1, 1)) %&gt;%
  select(Subject, A, Reaction)
example$A &lt;- as.factor(example$A)</pre>

<<<<<<< HEAD
<p><img src="RMANOVA_MLM-9_files/figure-html/unnamed-chunk-23-1.png" width="720" /></p>

</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section-20">
=======
<p><img src="RMANOVA_MLM-9_files/figure-html/unnamed-chunk-25-1.png" width="720" /></p>

</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section-22">
>>>>>>> 780f7577a252270721a2bdb46a39555798d4bcf9

<pre class = 'prettyprint lang-r'>ex.1 &lt;- lmer(Reaction ~ A + (1|Subject), data = example)
summary(ex.1)</pre>

<pre >## Linear mixed model fit by REML t-tests use Satterthwaite approximations
##   to degrees of freedom [lmerMod]
## Formula: Reaction ~ A + (1 | Subject)
##    Data: example
## 
## REML criterion at convergence: 1813.8
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -2.5154 -0.6952  0.0217  0.6144  3.5380 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  Subject  (Intercept) 1358     36.85   
##  Residual             1163     34.11   
## Number of obs: 180, groups:  Subject, 18
## 
## Fixed effects:
##             Estimate Std. Error      df t value Pr(&gt;|t|)    
## (Intercept)  271.630      9.400  19.780   28.90   &lt;2e-16 ***
## A1            53.755      5.085 161.010   10.57   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##    (Intr)
## A1 -0.270</pre>

<<<<<<< HEAD
</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section-21">
=======
</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section-23">
>>>>>>> 780f7577a252270721a2bdb46a39555798d4bcf9

<pre class = 'prettyprint lang-r'>library(sjPlot)
sjp.lmer(ex.1, facet.grid = FALSE,
          sort = &quot;sort.all&quot;)</pre>

<<<<<<< HEAD
<p><img src="RMANOVA_MLM-9_files/figure-html/unnamed-chunk-25-1.png" width="720" /></p></article></slide>
=======
<p><img src="RMANOVA_MLM-9_files/figure-html/unnamed-chunk-27-1.png" width="720" /></p></article></slide>
>>>>>>> 780f7577a252270721a2bdb46a39555798d4bcf9


  <slide class="backdrop"></slide>

</slides>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!-- map slide visiblity events into shiny -->
<script>
  (function() {
    if (window.jQuery) {
       window.jQuery(document).on('slideleave', function(e) {
         window.jQuery(e.target).trigger('hidden');
      });
       window.jQuery(document).on('slideenter', function(e) {
         window.jQuery(e.target).trigger('shown');
      });
    }
  })();
</script>

</body>
</html>
